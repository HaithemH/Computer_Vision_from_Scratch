{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <div align=\"center\">Perceptrons</div>\n",
    "---------------------------------------------------------------------\n",
    "\n",
    "you can Find me on Github:\n",
    "> ###### [ GitHub](https://github.com/lev1khachatryan)\n",
    "\n",
    "<img src=\"asset/1.1/main.png\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's a type of artificial neuron. Perceptrons were developed in the 1950s and 1960s by the scientist ***Frank Rosenblatt***, inspired by earlier work by Warren McCulloch and Walter Pitts. Today, it's more common to use other models of artificial neurons. In much modern work on neural networks, the main neuron model used is one called the ***sigmoid neuron***. But to understand why sigmoid neurons are defined the way they are, it's worth taking the time to first understand perceptrons.\n",
    "\n",
    "\n",
    "***Perceptron is a single layer neural network and a multi-layer perceptron is called Neural Networks.***\n",
    "\n",
    "Perceptron is a linear classifier (binary). Also, it is used in supervised learning. It helps to classify the given input data. \n",
    "Perceptron is usually used to classify the data into two parts. Therefore, it is also known as a ***Linear Binary Classifier***.\n",
    "\n",
    "\n",
    "So how do perceptrons work? A perceptron takes several binary inputs, x1,x2,…, and produces a single binary output:\n",
    "\n",
    "<img src=\"asset/1.1/1.png\" />\n",
    "\n",
    "In the example shown the perceptron has three inputs, x1,x2,x3. In general it could have more or fewer inputs. Rosenblatt proposed a simple rule to compute the output. He introduced weights, w1,w2,…, real numbers expressing the importance of the respective inputs to the output. The neuron's output, 0 or 1, is determined by whether the weighted sum ***∑j wjxj*** is less than or greater than some threshold value. Just like the weights, the threshold is a real number which is a parameter of the neuron. To put it in more precise algebraic terms:\n",
    "\n",
    "<img src=\"asset/1.1/2.png\" />\n",
    "\n",
    "That's all there is to how a perceptron works!\n",
    "\n",
    "That's the basic mathematical model. A way you can think about the perceptron is that it's a device that makes decisions by weighing up evidence. Let me give an example. It's not a very realistic example, but it's easy to understand, and we'll soon get to more realistic examples. Suppose the weekend is coming up, and you've heard that there's going to be a cheese festival in your city. You like cheese, and are trying to decide whether or not to go to the festival. You might make your decision by weighing up three factors:\n",
    "\n",
    "1. Is the weather good?\n",
    "2. Does your boyfriend or girlfriend want to accompany you?\n",
    "3. Is the festival near public transit? (You don't own a car).\n",
    "\n",
    "We can represent these three factors by corresponding binary variables x1,x2, and x3. For instance, we'd have x1=1 if the weather is good, and x1=0 if the weather is bad. Similarly, x2=1 if your boyfriend or girlfriend wants to go, and x2=0 if not. And similarly again for x3 and public transit.\n",
    "\n",
    "Now, suppose you absolutely adore cheese, so much so that you're happy to go to the festival even if your boyfriend or girlfriend is uninterested and the festival is hard to get to. But perhaps you really loathe bad weather, and there's no way you'd go to the festival if the weather is bad. You can use perceptrons to model this kind of decision-making. One way to do this is to choose a weight w1=6 for the weather, and w2=2 and w3=2 for the other conditions. The larger value of w1 indicates that the weather matters a lot to you, much more than whether your boyfriend or girlfriend joins you, or the nearness of public transit. Finally, suppose you choose a threshold of 5 for the perceptron. With these choices, the perceptron implements the desired decision-making model, outputting 1 whenever the weather is good, and 0 whenever the weather is bad. It makes no difference to the output whether your boyfriend or girlfriend wants to go, or whether public transit is nearby.\n",
    "\n",
    "By varying the weights and the threshold, we can get different models of decision-making. For example, suppose we instead chose a threshold of 3. Then the perceptron would decide that you should go to the festival whenever the weather was good or when both the festival was near public transit and your boyfriend or girlfriend was willing to join you. In other words, it'd be a different model of decision-making. Dropping the threshold means you're more willing to go to the festival."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obviously, the perceptron isn't a complete model of human decision-making! But what the example illustrates is how a perceptron can weigh up different kinds of evidence in order to make decisions. And it should seem plausible that a complex network of perceptrons could make quite subtle decisions:\n",
    "\n",
    "<img src=\"asset/1.1/3.png\" />\n",
    "\n",
    "In this network, the first column of perceptrons - what we'll call the first layer of perceptrons - is making three very simple decisions, by weighing the input evidence. What about the perceptrons in the second layer? Each of those perceptrons is making a decision by weighing up the results from the first layer of decision-making. In this way a perceptron in the second layer can make a decision at a more complex and more abstract level than perceptrons in the first layer. And even more complex decisions can be made by the perceptron in the third layer. In this way, a many-layer network of perceptrons can engage in sophisticated decision making.\n",
    "\n",
    "Incidentally, when I defined perceptrons I said that a perceptron has just a single output. In the network above the perceptrons look like they have multiple outputs. In fact, they're still single output. The multiple output arrows are merely a useful way of indicating that the output from a perceptron is being used as the input to several other perceptrons. It's less unwieldy than drawing a single output line which then splits.\n",
    "\n",
    "Let's simplify the way we describe perceptrons. The condition ∑jwjxj>threshold is cumbersome, and we can make two notational changes to simplify it. The first change is to write ∑jwjxj as a dot product, w⋅x≡∑jwjxj, where w and x are vectors whose components are the weights and inputs, respectively. The second change is to move the threshold to the other side of the inequality, and to replace it by what's known as the perceptron's bias, b≡−threshold. Using the bias instead of the threshold, the perceptron rule can be rewritten:\n",
    "\n",
    "<img src=\"asset/1.1/4.png\" />\n",
    "\n",
    "You can think of the bias as a measure of how easy it is to get the perceptron to output a 1. Or to put it in more biological terms, the bias is a measure of how easy it is to get the perceptron to fire. For a perceptron with a really big bias, it's extremely easy for the perceptron to output a 1. But if the bias is very negative, then it's difficult for the perceptron to output a 1. Obviously, introducing the bias is only a small change in how we describe perceptrons, but we'll see later that it leads to further notational simplifications. Because of this, in the remainder of the book we won't use the threshold, we'll always use the bias.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I've described perceptrons as a method for weighing evidence to make decisions. Another way perceptrons can be used is to compute the elementary logical functions we usually think of as underlying computation, functions such as AND, OR, and NAND. For example, suppose we have a perceptron with two inputs, each with weight −2, and an overall bias of 3. Here's our perceptron:\n",
    "\n",
    "<img src=\"asset/1.1/5.png\" />\n",
    "\n",
    "Then we see that input 00 produces output 1, since (−2)∗0+(−2)∗0+3=3 is positive. Here, I've introduced the ∗ symbol to make the multiplications explicit. Similar calculations show that the inputs 01 and 10 produce output 1. But the input 11 produces output 0, since (−2)∗1+(−2)∗1+3=−1 is negative. And so our perceptron implements a NAND gate!\n",
    "\n",
    "The NAND example shows that we can use perceptrons to compute simple logical functions. In fact, we can use networks of perceptrons to compute any logical function at all. The reason is that the NAND gate is universal for computation, that is, we can build any computation up out of NAND gates. For example, we can use NAND gates to build a circuit which adds two bits, x1 and x2. This requires computing the bitwise sum, x1⊕x2, as well as a carry bit which is set to 1 when both x1 and x2 are 1, i.e., the carry bit is just the bitwise product x1x2:\n",
    "\n",
    "<img src=\"asset/1.1/6.png\" />\n",
    "\n",
    "To get an equivalent network of perceptrons we replace all the NAND gates by perceptrons with two inputs, each with weight −2, and an overall bias of 3. Here's the resulting network. Note that I've moved the perceptron corresponding to the bottom right NAND gate a little, just to make it easier to draw the arrows on the diagram:\n",
    "\n",
    "<img src=\"asset/1.1/7.png\" />\n",
    "\n",
    "One notable aspect of this network of perceptrons is that the output from the leftmost perceptron is used twice as input to the bottommost perceptron. When I defined the perceptron model I didn't say whether this kind of double-output-to-the-same-place was allowed. Actually, it doesn't much matter. If we don't want to allow this kind of thing, then it's possible to simply merge the two lines, into a single connection with a weight of -4 instead of two connections with -2 weights. (If you don't find this obvious, you should stop and prove to yourself that this is equivalent.) With that change, the network looks as follows, with all unmarked weights equal to -2, all biases equal to 3, and a single weight of -4, as marked:\n",
    "\n",
    "<img src=\"asset/1.1/8.png\" />\n",
    "\n",
    "Up to now I've been drawing inputs like x1 and x2 as variables floating to the left of the network of perceptrons. In fact, it's conventional to draw an extra layer of perceptrons - the input layer - to encode the inputs:\n",
    "\n",
    "<img src=\"asset/1.1/9.png\" />\n",
    "\n",
    "This notation for input perceptrons, in which we have an output, but no inputs,\n",
    "\n",
    "<img src=\"asset/1.1/10.png\" />\n",
    "\n",
    "is a shorthand. It doesn't actually mean a perceptron with no inputs. To see this, suppose we did have a perceptron with no inputs. Then the weighted sum ∑jwjxj would always be zero, and so the perceptron would output 1 if b>0, and 0 if b≤0. That is, the perceptron would simply output a fixed value, not the desired value (x1, in the example above). It's better to think of the input perceptrons as not really being perceptrons at all, but rather special units which are simply defined to output the desired values, x1,x2,….\n",
    "\n",
    "The adder example demonstrates how a network of perceptrons can be used to simulate a circuit containing many NAND gates. And because NAND gates are universal for computation, it follows that perceptrons are also universal for computation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ***computational universality*** of perceptrons is simultaneously reassuring and disappointing. It's reassuring because it tells us that networks of perceptrons can be as powerful as any other computing device. But it's also disappointing, because it makes it seem as though perceptrons are merely a new type of NAND gate. That's hardly big news!\n",
    "\n",
    "However, the situation is better than this view suggests. It turns out that we can devise learning algorithms which can automatically tune the weights and biases of a network of artificial neurons. This tuning happens in response to external stimuli, without direct intervention by a programmer. These learning algorithms enable us to use artificial neurons in a way which is radically different to conventional logic gates. Instead of explicitly laying out a circuit of NAND and other gates, our neural networks can simply learn to solve problems, sometimes problems where it would be extremely difficult to directly design a conventional circuit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <div align=\"center\">Perceptron: Classification algorithm</div>\n",
    "---------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the Problem\n",
    "\n",
    "In the data set we have 150 samples of 3 flowers with 4 features, \"petal length\", \"petal width\", \"sepal length\", and \"sepal width\". Given a sample of features we would like to predict which of the 3 flowers it is. For example, if we know that petal length is 0.3, and sepal length is 0.5 then it must be an Iris-setosa.\n",
    "\n",
    "To make this prediction we will train a Perceptron algrothim.\n",
    "\n",
    "### Prepare and Explore the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>SepalLengthCm</th>\n",
       "      <th>SepalWidthCm</th>\n",
       "      <th>PetalLengthCm</th>\n",
       "      <th>PetalWidthCm</th>\n",
       "      <th>Species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id  SepalLengthCm  SepalWidthCm  PetalLengthCm  PetalWidthCm      Species\n",
       "0   1            5.1           3.5            1.4           0.2  Iris-setosa\n",
       "1   2            4.9           3.0            1.4           0.2  Iris-setosa\n",
       "2   3            4.7           3.2            1.3           0.2  Iris-setosa\n",
       "3   4            4.6           3.1            1.5           0.2  Iris-setosa\n",
       "4   5            5.0           3.6            1.4           0.2  Iris-setosa"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris_data = pd.read_csv(\"input/1.1/Iris.csv\")\n",
    "iris_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use two features: **sepal length** and **petal length**, to classify two flowers(out of 3) , **Setosa** and **Versicolor**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Restricting data set to two features and two flowers\n",
    "features  = ['SepalLengthCm', 'PetalLengthCm']\n",
    "flowers   = ['Iris-setosa', 'Iris-versicolor']\n",
    "iris_data = iris_data[ features + ['Species']]\n",
    "\n",
    "iris_data = iris_data[iris_data['Species'].isin(flowers)] #only selecting two flowers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, to assist our algorithm label **Setosa** as '1' to indicate a match, and **Versicolor** as -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris_data['Classification'] = np.where(iris_data['Species'] == 'Iris-setosa', 1, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SepalLengthCm</th>\n",
       "      <th>PetalLengthCm</th>\n",
       "      <th>Species</th>\n",
       "      <th>Classification</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>1.4</td>\n",
       "      <td>Iris-setosa</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>1.4</td>\n",
       "      <td>Iris-setosa</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>1.3</td>\n",
       "      <td>Iris-setosa</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>1.5</td>\n",
       "      <td>Iris-setosa</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>Iris-setosa</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   SepalLengthCm  PetalLengthCm      Species  Classification\n",
       "0            5.1            1.4  Iris-setosa               1\n",
       "1            4.9            1.4  Iris-setosa               1\n",
       "2            4.7            1.3  Iris-setosa               1\n",
       "3            4.6            1.5  Iris-setosa               1\n",
       "4            5.0            1.4  Iris-setosa               1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXwAAAEKCAYAAAARnO4WAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAIABJREFUeJzt3X+UVPWZ5/H3A40BjIIRJqswLTjrj4jNz8ZInA0oRo0o8Rw1MWOGSOJhDRt+mNVRJ2elNfFkMsZVshud4G+jE3HQmBgTYyRxDFlHpQ3SGsS4Koq4ETG0aMQA/ewfVQXVRXX3vVX1rbq37+d1Th363rp966lb9NO3n+d+v9fcHRER6f8GNDoAERGpDyV8EZGMUMIXEckIJXwRkYxQwhcRyQglfBGRjFDCFxHJCCV8EZGMUMIXEcmIpkYHUGzEiBE+ZsyYRochIpIa7e3tb7n7yCjbJirhjxkzhtWrVzc6DBGR1DCzDVG3VUlHRCQjlPBFRDJCCV9EJCOU8EVEMkIJX0QkI5TwRVKq9N5FupeR9EUJXySF2trgwgv3JHn33HJbWyOjkqRTwhdJGXfYuhWWLt2T9C+8MLe8davO9KVniRp4JSJ9M4Nrr819vXRp7gGwaFFuvVnjYpNksyTdxLy1tdU10lYkGncYUPQ3eleXkn0WmVm7u7dG2TZoScfMXjGzDjNbY2bK5CI1UijjFCuu6UvPstzsrkcN/3h3nxj1N5CI9K64Zr9oUe7MftGi7jV9KS/rzW7V8EVSxgyGD+9esy/U9IcPV1mnJ8XNbsgds+JfnO79/9gFreGb2cvAnwAHvu/uy3rbXjV8kehKE1QWEla1iv86Kkh7sztODT90wj/Y3TeZ2V8BvwQWuPtjJdvMA+YBNDc3T9mwIfJMnyLSYGn8pROq2d2oY5GYpq27b8r/+ybwI+CYMtssc/dWd28dOTLSHP4ikgBprIeHanan5VgES/hmtq+Z7Vf4GjgJeDbU64lI/aRx8FeoZneajkXIpu1HgR9Z7m+aJuBf3f2hgK8nInWSxsFfoZrdaToWGnglIhVL4+CvULX2Rh2LxNTwRSSeNA0KSuvgr9Ik3FtSjvp5pOVYKOGLJERaGn+QjcFfUT+PNB0LDbwSSYC0DQrq74O/4nweaToWquGLJEQaBwWl8Tr8qOJ+Hmm4Dl8JXyRB0tgE7c/S8HmoaSuSQiEbf11dvS9XKk1N5oIkNGIbddyU8EUSIGTjb8YMmDJlT5Lv6sotz5hRXcxpajIXJKER28jjpoQvkgA9Nf4WLaqu8dfVBZ2dsGbNnqQ/ZUpuubOz8jP9NI0uLYgTc6jPo+HHzd0T85gyZYqLZFlXV+/Lldi1y33iRPdcOsk9Jk7Mra9GV5f7okXd97toUW1iDiVuzCE+j1ofN2C1R8yxatqKZEBXFwwcuGd5167uzchKpaGpWSoJMdcyBjVtRWS3ri6YPLn7usmTq2/chh5dGqexmYRGbFSNjEEJX6Qf6+qCgw+GZ56BCRNyZ/YTJuSWDz64uhp+yNGlcRqbSWjERtXoGDTSVqQfM4Om/E/59Om55enTcwm/qam6GSJDjS6NM8o1bSNiGx5D1GJ/PR5q2orUXleX+8KF3ZuECxfWrgHZ23I1+43a2ExCIzauWsaAmrYiUiwJjcq44sScxvdXK2raSr8Vp5EXar+hYogr6ujZuE3CpBzjqDEnoRGbFkr4khqhRiiGaBCGFnX0bNwmYRKOcZyYG90ETRslfEmF4uZcLUcoxtlvqBjiijN6Ns6I0SQc47gxhxoR229FLfbX46GmrfQm1MjOkA3CUOKOno3aJEzCMY4bc9xt+xvUtJX+Km4jL+r85GlsECZh9GyoYxxX3Dj60xz+atpKvxSnOVdJzTjKfpPSICyUcYoV1/QrlYRjHFcaezANE/VPgXo8VNKRnhSXBAqlgNLlJG0bUnE5p1DGKV2uRBqPW1LiaCRilHQanuSLH0r40pslS7r/YBZ+YJcs2XvbODXjOPuNs21I06d3T+6FpD99enX7TcIxjiuNPZhaipPwVcOXVPGAdfm01YC7uvZ+f7Wq4Tf6GMcVN44k9GBqRTV86bdKfzB7+6GOUzOOut+424ZUmtxrkezjiHuMkxBHUmJumKh/CtTjoZKO1EJ/rdXWQ9TSS9xjHKqkoxp+vJKOZsuUfqfhMxKmlHuYmSfj7DeuOHHo/wWq4Uv/lZRae5oUSh6F5AzdE2S57aMc47j7rSTutPVgaiVODV8JX0S6CdXU7G/N0qRQ01YkptLznt7Og6LOUhk6jhBCNTUz3yxNCCV8ybw4oy+jzlIZOo4QissutZx5MtR+JT4lfMm04oZiXzM5xpmlMmQcoYSaeVIzWiaHaviSeXEaisVJvmDiRGhvr/46+NCNzThxhGhq9rdmaVKoaSsSU5yGYqhZKuPGIQJq2orE4g6LF3dft3hx+TJKVxdMntx93eTJvd9esLfl0ufU2JSQlPAl09xh2jT47ndh4cJc4l64MLc8bdreNfyDD4ZnnoEJE3Jn9hMm5JYPPnjvpB/qtn4ilVLCF4nIDJryY9OnT88tT5+eW25qqu52gWpsSl1EnYOhHg/NpSON0NXlvnChd5syd+HCnqfXjbNtyNv6ibjHm0tHTVsRwk2vqyashJaopq2ZDTSz35nZT0O/lkixqCNi4zRL424btRlcibgN4ajbSv9Vjxr+ImBdHV5HZLeoI2LjNEvjbhu1GVwJ3cdVKhE04ZvZaGAWcFPI1xEpFmdEbJxmaVIaq3EawkkYwSsJErXYX8kDWAFMAWYAP+1rezVtpVaKb+xdePR2g+84zdKo28Zp8MaV9fu4yh4koWlrZqcBp7r7fDObAVzk7qeV2W4eMA+gubl5yoYNG4LEI/XjCRlCH2dEbKiYkzIqV83j/ispTdvjgNlm9gpwN3CCmd1ZupG7L3P3VndvHTlyZMBwpB6SUi8ulHGKFdf0i4WKecmS8jEsWVLdfiFco1n6uah/ClTzQCWdTEjKPUOLyzmFMk7pcuiY48QQl+7jKsXQPW2lEYrvEbp06Z5ZH+s94+OAATBsWPdZLNvbc2fXw4Z1L22EinnAAJg9O/f1mjV7yjoTJ+bWV1PW0X1cpVIaeCU1l5R6cVfX3nH0VsMPEXPoGn5W7+MqeySlhi8ZlKR6cWlC6y0Zhrqt39e+1n3d175Wu2MR9f3F3Vb6LyV8qZlC4kzCjI9RG7GhYk7SsRApUA1faiYp9WIvGmwEuRiKk29xOSNUzEk5FiLFVMOXmktCvbj4DLugt0ZsqJiTcCykf9MtDkVITvNYJCQ1bSXzPPBMlSJppIQv/Y4HnqlSJK2U8EVEMkIJX/odM3j88T1n9QMG7Dnbf/xx1fElu9S0lX5LTVvJAjVtJfPijp4tXZ+g8yCRmukz4ZvZcWb2SzN7wcxeMrOXzeylegQnUom4o1yTMqWzSGhRRtreDFwItAO7woYjUr04o1zjjMoVSbs+a/hm9oS7f7wewaiGL7UUdZRr3FG5IklSk5G2ZjY5/+VngYHAfcAHhefd/ekq49yLEr40ihq8klZxEn5vJZ1rSpaLd+jACXEDk2TRPC85PTV46z3vjkhoPSZ8dz8ewMwOdfduTVozOzR0YBJWW1uudl1IaoWkN3x4tpqVpQ3e4ho+7J30ddwkzaJclrmizLp/q3UgUj/FjcrC1SmFJLd1a7YuSeypwbtoUe8N3qwfN0mn3mr4RwLjgH8GLi56an/gYncfV+tgVMOvHzUqu1ODV9KqVk3bzwBnALOBnxQ9tQ24293/T7WBllLCry81Kiuj4yZJUpORtu7+Y3efC5zm7nOLHgtDJHupryTdezZNdNwkzaLU8P/OzL5b8vhG/i8ASSHdb7UyOm6SdlFG2n4IOJI9jdozgeeAL5vZ8e6+uMfvlETS/VYro+MmaRdlpO2vgJPcfWd+uQl4GPgU0OHuR9UqGNXw60vXk1dGx02SpNazZY4C9i1a3hc42N13UTTyVpJBsz6GV5rclewlLaIk/H8G1pjZrWZ2G/A74Dtmti/wSMjgJJ44sz5qhkiR7Okz4bv7zcAngPvzj79195vc/T13v7j375Z6iTMoSAOIRLIp0h2vzGwUcAhFTV53f6zWwaiGX504g4I0gEikf6jJwKuinX0b+By5K3O68qvd3WdXFWUZSvjVizMoSAOIRNKv1k3bM4Aj3H2Wu5+ef9Q82Uv14gwK0gAikeyJkvBfAgaFDkSqE2dQkAYQiWRTlIFXfyZ3lc5Kut8AZWGwqCS2OIOCNIBIJJui1PC/WG69u99e62BUw69enEFBGkAkkn61uuMVkEvsZjYEaHb39VVHJ0HFGRSkAUQi2dJnDd/MTgfWAA/llyea2U96/y4REUmaKE3bNuAYYCuAu68BxgaMSUREAoiS8He6e2fJOl3HISKSMlGu0nnWzP4OGGhmhwELAd0ARUQkZaKc4S8gd2/bD4AfAu8AmgM/YzQLp0j6RblK58/A1/OPyMxsMPAYuRuoNAEr3H1JJUFKY7W15SZVK1yzXxi4NXy4ZtcUSZMeE76ZPUAvtfoI0yt8AJzg7u+a2SBglZn93N3/o7JQpRGKZ9aEXNIvHqWra/dF0qO3M/zvVLNjz43oeje/OCj/UCEgZYpH4S5duifxa2ZNkfSJND1yxTs3Gwi0A/8Z+J67X1Jmm3nAPIDm5uYpGzZsCBaPVE4za4okU61ny6yYu+9y94nAaOAYMzu6zDbL3L3V3VtHjhwZMhypkGbWFOkfgib8AnffCjwKnFKP15Pa0cyaIv1HlOvwK2JmI4Ed7r41PxfPicC3Q72ehKGZNUX6j5BX6RwE3J6v4w8A7nH3n1YUpTRUW1v3q3EKSV/JXiRdQl6lsxaYVM0+JDk0s6ZI+vWY8N393+sZiIiIhNVnDT8/f863gKOAwYX17n5owLhERKTGolylcytwA7ATOB64A/hByKBERKT2oiT8Ie6+ktwgrQ3u3gacEDYsERGptSiXZW43swHAH8zsq8DrwF+FDUtERGotyhn+YmAouXnwpwB/D5S9sbmIiCRXlOmRnwLIn+UvdPdtwaMSEZGai3IT81Yz6wDWAh1m9oyZTQkfmoiI1FKUGv4twHx3/w2Amf0tuSt3xocMTEREaitKDX9bIdkDuPsqQGUdEZGUiXKG/6SZfZ/c/Wwd+BzwqJlNBnD3pwPGJyIiNRIl4U/M/1t6P9pPkPsFoGvyRURSIMpVOsfXIxAREQkrylU6HzWzm83s5/nlo8zsy+FDExGRWorStL0N+AVwcH75BXKDsUREJEWiJPwR7n4P0AXg7juBXUGjEhGRmouS8N8zswPJ3/3KzI4FOoNGJSIiNRflKp2vAT8B/sbMfguMBM4KGpWIiNRclKt0njaz6cARgAHr3X1H8MhERKSmolylcza5OfGfA84AlhcGXYmISHpEqeH/D3fflp9D52TgdnJ3wBIRkRSJkvALV+TMAm5w9x8D+4QLSUREQoiS8F/Pz6XzWeBnZvahiN8nIiIJEiVxf5bcwKtT3H0r8BHg4qBRiYhIzUW5SufPwH1Fy28Ab4QMSkREak+lGRGRjFDCFxHJCCV8EZGMUMIXEckIJXwRkYxQwhcRyQglfBGRjFDCFxHJCCV8EZGMUMIXEckIJXwRkYxQwhcRyQglfBGRjFDCFxHJiGAJ38z+2sx+bWbrzOw5M1sU6rVERKRvfc6HX4WdwH9396fNbD+g3cx+6e6/D/iaIiLSg2Bn+O7+hrs/nf96G7AOGBXq9UREpHd1qeGb2RhgEvBEmefmmdlqM1u9efPmeoQjIpJJwRO+mX0YuBdY7O7vlD7v7svcvdXdW0eOHBk6HBGRzApZw8fMBpFL9ne5+319bS/lddzVwcqvr6Tz1U6GNQ9j5lUzaTm3JXMxiEh1giV8MzPgZmCdu//PUK/T33Xc1cED8x5gx593ANC5oZMH5j0AULeEm4QYRKR6IUs6xwF/D5xgZmvyj1MDvl6/tPLrK3cn2oIdf97Byq+vzFQMIlK9YGf47r4KsFD7z4rOVztjre+vMYhI9TTSNuGGNQ+Ltb6/xiAi1VPCT7iZV81k0NBB3dYNGjqImVfNzFQMIlK9oFfpSPUKTdFGXiGThBhEpHrm7o2OYbfW1lZfvXp1o8MQEUkNM2t399Yo26qkIyKSEUr4IiIZoRq+RJKUkbYPzn+Q9mXt+C7HBhpT5k1h1vWz6hpDUo6FSFxK+NKnpIy0fXD+g6y+YU+Px3f57uV6Jf2kHAuRSqikI31Kykjb9mXtsdaHkJRjIVIJJXzpU1JG2vqu8leU9bQ+hKQcC5FKKOFLn5Iy0tYGlp+po6f1ISTlWIhUQjX8Bojb9AvVqLzjxDt4eeXLu5fHzhzLnEfm7LXdzKtmcv/c++na0bV73YBBA+o+0nbKvCndavjF6+tl5lUzu9XwQaOOJT10hl9nhaZf54ZO8D1Nv467OspuX2hUFsoWhUblg/MfrCqO0mQP8PLKl7njxDvKbp+b7brn5XqYdf0sWr/SuvuM3gYarV9pretVOi3ntnD6stMZdsgwMBh2yDBOX3a6GraSChppW2fXjbkul+xLDDtkGItfWbzX+iubrixbo7aBxuU7L684jivsih6fW+JLui3HjVlE6kcjbRMsbtNPjUoRqRXV8Gskal1+WPOw8mfLPTT9bKD1eIZfTtS6fBxxY47bc4jT09DAq3TZsWMHGzduZPv27Y0OJfUGDx7M6NGjGTRoUN8b90AJvwbiDMaJ2/SL06jsrS5fmvRHHDWCt37/1l77GHHUiL3WDdq3/H+wcuvjDo6Kc+w08Cp9Nm7cyH777ceYMWMa0vfpL9ydLVu2sHHjRsaOHVvxflTSqYE4g3HiNv3iNCpLk31v63e8t6PMluXXl/vF0NP6uIOj4hw7DbxKn+3bt3PggQcq2VfJzDjwwAOr/ktJZ/g1ELfG3XJuS6yzwVnXz6r5GWyounzcnkOcONTPSCcl+9qoxXHUGX4NpHEwTqiY4w6OihOHBl5JSLfddhubNm1qdBhBZS7hd9zVwXVjruOKAVdw3Zjrerz+PY6ZV83c+0gOoGaDcR6c/yBXNl3JFXYFVzZd2eM1+GNnlq/tlVs/86qZeyVKG2hlY46z354GQfW0Ps7tE+PuO9Rnrds99k9K+P1M3EFPUb3621ehq2RlV359leIMvJo0d1LZfZRb/+pvX92rFOK7vGzMBx5+YNn9llvffFxz2V8kzcc1l91HnJ5GnH5GqM9aA6/CqvUv6ffee49Zs2YxYcIEjj76aJYvX057ezvTp09nypQpnHzyybzxxhusWLGC1atXc+655zJx4kTef/99Vq5cyaRJk2hpaeFLX/oSH3zwAQCXXnopRx11FOPHj+eiiy4C4IEHHuDjH/84kyZN4sQTT+SPf/xj1ccihEwNvAo1gCjU4Ki4+47z/uLsN1QMISUljqxbt24dH/vYxyJtW3oFFOT+eqrmF+q9997LQw89xI033ghAZ2cnn/70p/nxj3/MyJEjWb58Ob/4xS+45ZZbmDFjBt/5zndobW1l+/btHHbYYaxcuZLDDz+cOXPmMHnyZObMmcO0adN4/vnnMTO2bt3K8OHD+dOf/sTw4cMxM2666SbWrVvHNddcU1HMvSl3PDXwqgdJaVSG2neoBmioGEJKShwSXYgroFpaWnjkkUe45JJL+M1vfsNrr73Gs88+y6c+9SkmTpzIN7/5TTZu3LjX961fv56xY8dy+OGHA/DFL36Rxx57jP3335/Bgwdz/vnnc9999zF06FAgd/npySefTEtLC1dffTXPPfdcxTGHlKmEn5RGZah9h2qAhoohpKTEIdGF+CV9+OGH097eTktLC5dddhn33nsv48aNY82aNaxZs4aOjg4efvjhvb6vp8pHU1MTTz75JGeeeSb3338/p5xyCgALFizgq1/9Kh0dHXz/+99P7ECzTCX8uM3VqPXEkM3EOPsO1QANFUMloh67mVfNZMCg7h92I2b4lOhC/JLetGkTQ4cO5Qtf+AIXXXQRTzzxBJs3b+bxxx8HciOBC2fj++23H9u2bQPgyCOP5JVXXuHFF18E4Ac/+AHTp0/n3XffpbOzk1NPPZXrrruONWvWALlS0ahRowC4/fbbK443tExdh99bc7W0RhhnRGWhaRhlyH/ckZpx9l34/ijD/puPa969z4KemquhYogr7rFLwgyfEl2Iqac7Ojq4+OKLGTBgAIMGDeKGG26gqamJhQsX0tnZyc6dO1m8eDHjxo3jvPPO44ILLmDIkCE8/vjj3HrrrZx99tns3LmTqVOncsEFF/D222/zmc98hu3bt+PuXHvttQC0tbVx9tlnM2rUKI499lhefrn8IMhGy1TTNgnNx6Q0E5MSRxxxYk7j++uP4jRtQfMU9aXapm2mzvCT0HxMSjMxKXHEESfmNL4/iT8KXeLJVA0/Cc3HpDQTkxJHHHFiTuP7EwktUwk/Cc3HpIzUnHnVTAbuM7DbuoH7DEx0UzPOsUvKcQ4x2lekUpkq6SSh+RiyqRlXaf8mSf2ccuIcuyQcZ02lLEmTqaat7KGmZng6xvGbttI7jbSViqipGZ6OsSRNv0j4qpPGp6ZmeDrG/dPll1/OI488Evv7Hn30UU477bQAEUWX+oQfalbE/i4pTc3+TMc4vtIKc6Mqzu5OV1fpKM2cK6+8khNPPDF4DDt37qz5PlOf8HXLucpomt/wdIzjaWuDCy/ck+Tdc8ttbZXv85JLLuH6668veo02rrnmGq6++mqmTp3K+PHjWbJkCQCvvPIKH/vYx5g/fz6TJ0/mtdde47zzzuPoo4+mpaVl96ja8847jxUrVgDw1FNP8YlPfIIJEyZwzDHHsG3bNrZv387cuXNpaWlh0qRJ/PrXv94rrrfffpszzjiD8ePHc+yxx7J27drd8c2bN4+TTjqJOXPm7PV91Ur9VTqqk1ZOg1zC0zGOxh22boWlS3PL116bS/ZLl8KiRbnnK5kZ45xzzmHx4sXMnz8fgHvuuYdLL72UVatW8eSTT+LuzJ49m8cee4zm5mbWr1/PrbfeyvXXX097ezuvv/46zz77LABbt27ttu+//OUvfO5zn2P58uVMnTqVd955hyFDhrA0/yY6Ojp4/vnnOemkk3jhhRe6fe+SJUuYNGkS999/P7/61a+YM2fO7nl52tvbWbVqFUOGDIn/hvuQ+oQ/rHlY+SshVCcVSQ2zXJKHXJIvJP5Fi3LrK50GadKkSbz55pts2rSJzZs3c8ABB7B27VoefvhhJk3K3Rjo3Xff5Q9/+APNzc0ccsghHHvssQAceuihvPTSSyxYsIBZs2Zx0kknddv3+vXrOeigg5g6dSoA+++/PwCrVq1iwYIFQG4StkMOOWSvhL9q1SruvfdeAE444QS2bNlCZ2cuj82ePTtIsoeAJR0zu8XM3jSzZ0O9BiSnTqrGsUh1ipN+QTXJvuCss85ixYoVLF++nHPOOQd357LLLts9RfKLL77Il7/8ZQD23Xff3d93wAEH8MwzzzBjxgy+973vcf7553fbr7uXnZAvyqXu5bYp7Ks4hloLWcO/DTgl4P6BZNRJ1TgWqV6hZl+suKZfqXPOOYe7776bFStWcNZZZ3HyySdzyy238O677wLw+uuv8+abb+71fW+99RZdXV2ceeaZfOMb3+Dpp5/u9vyRRx7Jpk2beOqppwDYtm0bO3fu5JOf/CR33XUXAC+88AKvvvoqRxxxRLfvLd7m0UcfZcSIEbv/QggpWEnH3R8zszGh9l+s0XXS3hrHqt+K9K2Q7As1++IaPlR3pj9u3Di2bdvGqFGjOOiggzjooINYt24d06ZNA+DDH/4wd955JwMHdp9q5PXXX2fu3Lm7r9b51re+1e35ffbZh+XLl7NgwQLef/99hgwZwiOPPML8+fO54IILaGlpoampidtuu40PfehD3b63ra2NuXPnMn78eIYOHVq3OfSDjrTNJ/yfuvvRvWwzD5gH0NzcPGXDhg3B4gnligFXQLnDaLCka0nd4xFJijgjbdvaco3bQnIv/BIYPry6K3X6k9RPj+zuy4BlkJtaocHhVESNY5HqtbV1vxqnUNPXfWtqJ/XX4SdBUhrHImlXmtyV7Gur4Wf4/UESZmYUEelLsIRvZj8EZgAjzGwjsMTdbw71eo3W6MaxSFL1dPmixFOLfmvIq3Q+H2rfIpIOgwcPZsuWLRx44IFK+lVwd7Zs2cLgwYOr2o9KOiISzOjRo9m4cSObN29udCipN3jwYEaPHl3VPpTwRSSYQYMGMXbs2EaHIXm6SkdEJCOU8EVEMkIJX0QkIxJ1E3Mz2wwkcW6FEcBbjQ4iIL2/dNP7S69avLdD3H1klA0TlfCTysxWR52rIo30/tJN7y+96v3eVNIREckIJXwRkYxQwo9mWaMDCEzvL930/tKrru9NNXwRkYzQGb6ISEYo4Zcws4Fm9jsz+2mZ584zs81mtib/OL/cPpLKzF4xs4587KvLPG9m9l0ze9HM1prZ5EbEWakI72+GmXUWfX6XNyLOSpnZcDNbYWbPm9k6M5tW8nxqP78I7y21n52ZHVEU9xoze8fMFpdsU5fPTnPp7G0RsA7o6Y7Cy939q3WMp9aOd/eervv9NHBY/vFx4Ib8v2nS2/sD+I27n1a3aGprKfCQu59lZvsAQ0ueT/Pn19d7g5R+du6+HpgIuRNK4HXgRyWb1eWz0xl+ETMbDcwCbmp0LA3yGeAOz/kPYLiZHdTooATMbH/gk8DNAO7+F3ffWrJZKj+/iO+tv5gJ/F93Lx1gWpfPTgm/u+uAfwC6etnmzPyfXCvM7K/rFFetOPCwmbXnbx5fahTwWtHyxvy6tOjr/QFMM7NnzOznZjaunsFV6VBgM3BrvuR4k5ntW7JNWj+/KO8N0vvZFTsH+GGZ9XX57JTw88zsNOBNd2/vZbMHgDHuPh54BLi9LsHVznHuPpncn4//zcw+WfJ8uTtUpOkyrr7e39PkhqFPAP4XcH+9A6xCEzAZuMHdJwHvAZeWbJPWzy/Ke0vzZwdAvlQ1G/i3ck+XWVfzz04Jf4/jgNlm9gpwN3CCmd1ZvIG7b3H3D/KLNwJT6htiddxNs7qUAAADyUlEQVR9U/7fN8nVEI8p2WQjUPxXy2hgU32iq15f78/d33H3d/Nf/wwYZGYj6h5oZTYCG939ifzyCnJJsnSbNH5+fb63lH92BZ8Gnnb3P5Z5ri6fnRJ+nrtf5u6j3X0MuT+7fuXuXyjepqSmNptcczcVzGxfM9uv8DVwEvBsyWY/Aebkrxg4Fuh09zfqHGpForw/M/tPlr/PnpkdQ+7//5Z6x1oJd/9/wGtmdkR+1Uzg9yWbpfLzi/Le0vzZFfk85cs5UKfPTlfp9MHMrgRWu/tPgIVmNhvYCbwNnNfI2GL6KPCj/M9ME/Cv7v6QmV0A4O7/AvwMOBV4EfgzMLdBsVYiyvs7C/iKme0E3gfO8XSNPFwA3JUvDbwEzO1Hn19f7y3Vn52ZDQU+BfzXonV1/+w00lZEJCNU0hERyQglfBGRjFDCFxHJCCV8EZGMUMIXEckIJXzp9yw3y+nBEba7zczOirq+BnH9Y9HXY8ysdFyESE0p4UsWnAf0mfAb4B/73kSkdpTwJVXyZ8LPm9ntRZPYDc0/N8XM/j0/edovzOyg/Jl5K7lBPWvMbIiZXW5mT5nZs2a2rDCCM+Lr7/Ua+fWPmtm3zexJM3vBzP5Lfv1QM7snH+tyM3vCzFrN7J+AIfmY7srvfqCZ3Whmz5nZw2Y2pLZHT7JOCV/S6AhgWX4Su3eA+WY2iNykWme5+xTgFuAqd18BrAbOdfeJ7v4+8L/dfaq7Hw0MASLNsd7TaxRt0uTuxwCLgSX5dfOBP+Vj/Qb5+Zfc/VLg/XxM5+a3PQz4nruPA7YCZ8Y/NCI909QKkkavuftv81/fCSwEHgKOBn6ZP2EfCPQ0F8nxZvYP5G6y8RHgOXIzofbliD5e4778v+3AmPzXf0vu5h64+7NmtraX/b/s7mvK7EOkJpTwJY1K5wNxctPLPufu08psv5uZDQauB1rd/TUzawMGR3zdvl6jMJPqLvb8bEUuFxV9f2EfKulITamkI2nUbHvuefp5YBWwHhhZWG9mg4pukrEN2C//dSG5v2VmHyY3KVdUvb1GT1YBn81vfxTQUvTcjnyZSKQulPAljdYBX8yXRz5C7sYZfyGXvL9tZs8Aa4BP5Le/DfgXM1tD7iz6RqCD3E00nor6on28Rk+uJ/dLYi1wCbAW6Mw/twxYW9S0FQlKs2VKqpjZGOCn+YZr4lnuptWD3H27mf0NsBI4PP/LQ6SuVMMXCWso8Ot86caAryjZS6PoDF9EJCNUwxcRyQglfBGRjFDCFxHJCCV8EZGMUMIXEckIJXwRkYz4/1KEpJLmNt4iAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "setosa     = iris_data[iris_data['Species'] == 'Iris-setosa']\n",
    "versicolor = iris_data[iris_data['Species'] == 'Iris-versicolor']\n",
    "\n",
    "plt.scatter(setosa.SepalLengthCm, \n",
    "            setosa.PetalLengthCm, \n",
    "            color  ='purple',\n",
    "            marker ='o',\n",
    "            label  ='setosa')\n",
    "\n",
    "plt.scatter(versicolor.SepalLengthCm, \n",
    "            versicolor.PetalLengthCm, \n",
    "            color  ='blue',\n",
    "            marker ='x',\n",
    "            label  ='versicolor')\n",
    "\n",
    "plt.xlabel('petal length')\n",
    "plt.ylabel('sepal length')\n",
    "plt.legend(loc='lower right')\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the plot shows, the two flowers usually fall far apart from each other. If we can find a measure using a combination of **petal length** and **sepal length** then we should be able to classify any of the two flowers. For example, if petal length is 6.5 and sepal length is 4, then its likely a versicolor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Perceptron:\n",
    "    \n",
    "    def __init__(self, learning_rate=0.01, iterations=10):\n",
    "        self.learning_rate = learning_rate\n",
    "        self.iterations    = iterations\n",
    "        \n",
    "        self._weights      = None\n",
    "        self._errors       = []\n",
    "        self._threshold    = 0.0\n",
    "\n",
    "    \n",
    "    def fit(self, training_vector, target_value):\n",
    "        \"\"\"Fit training data\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        training_vector : {array-like}, shape = [samples, features]\n",
    "        target_value    : {array-life}, shape = [samples]\n",
    "        \"\"\"\n",
    "        numberOfSamples, numberOfFeatures = training_vector.shape\n",
    "        self._weights = np.zeros(numberOfFeatures)\n",
    "        \n",
    "        for _ in range(self.iterations):\n",
    "            errors = 0\n",
    "            for observation, target in zip(training_vector, target_value):\n",
    "                update          = self.learning_rate * (target - self.predict(observation))\n",
    "                self._weights  += update * observation\n",
    "                self._threshold = update\n",
    "                errors += int(update != 0.0)\n",
    "            self._errors.append(errors)\n",
    "            \n",
    "    def _net_input(self, training_vector):\n",
    "        \"\"\"Calculate net input\"\"\"\n",
    "        return np.dot(training_vector, self._weights)\n",
    "    \n",
    "    def predict(self, training_vector):\n",
    "        \"\"\"Return class label after unit step\n",
    "        Given an array of features, returns an array with \n",
    "        \"\"\"\n",
    "        #This is a confusing line. Explanation: \n",
    "        #np.where will first return indices of elements for which the net input is \n",
    "        #greater than the threshold. It will then mark them with 1 for match,\n",
    "        #or -1 for not a match.\n",
    "        # E.g  INPUT : training_vector = [10,2, -1, -2], threshold = 0\n",
    "        #      RETURN: np.array([1,1,-1,-1])\n",
    "        return np.where(self._net_input(training_vector)>= self._threshold, 1, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "test_fit (__main__.TestPreceptron) ... C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:60: FutureWarning: from_items is deprecated. Please use DataFrame.from_dict(dict(items), ...) instead. DataFrame.from_dict(OrderedDict(items)) may be used to preserve the key order.\n",
      "ok\n",
      "test_initialization (__main__.TestPreceptron) ... ok\n",
      "test_net_input (__main__.TestPreceptron) ... ok\n",
      "test_predict (__main__.TestPreceptron) ... C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:39: FutureWarning: from_items is deprecated. Please use DataFrame.from_dict(dict(items), ...) instead. DataFrame.from_dict(OrderedDict(items)) may be used to preserve the key order.\n",
      "ok\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 4 tests in 0.019s\n",
      "\n",
      "OK\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<unittest.runner.TextTestResult run=4 errors=0 failures=0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Testing\n",
    "import unittest\n",
    "class TestPreceptron(unittest.TestCase):\n",
    "    \n",
    "    def test_initialization(self):\n",
    "        \n",
    "        a_perceptron = Perceptron(learning_rate=0.5, iterations=10)\n",
    "        self.assertIsNotNone(a_perceptron)\n",
    "        self.assertEqual    (a_perceptron.learning_rate, 0.5)\n",
    "        self.assertEqual    (a_perceptron.iterations   ,  10)\n",
    "    \n",
    "    def test_net_input(self):\n",
    "         \n",
    "        a_perceptron    = Perceptron()\n",
    "        training_vector = pd.DataFrame({'feature1':[1,1], \n",
    "                                        'feature2':[0,1]})\n",
    "        a_perceptron._weights = [0,1]\n",
    "        self.assertTrue(np.array_equal(\n",
    "                        a_perceptron._net_input(training_vector), \n",
    "                        [0,1]))\n",
    "            \n",
    "        a_perceptron._weights = [2,2]\n",
    "        self.assertTrue(np.array_equal(\n",
    "                        a_perceptron._net_input(training_vector), \n",
    "                        [2,4]))\n",
    "        \n",
    "    def test_predict(self):\n",
    "        \n",
    "        a_perceptron    = Perceptron()\n",
    "        \n",
    "        columns = ['Classification', 'FeatureA', 'FeatureB']\n",
    "        data    = {'obs1': [ 1,0,1],\n",
    "                   'obs2': [ 1,0,1],\n",
    "                   'obs3': [-1,1,0],\n",
    "                   'obs4': [-1,1,0]\n",
    "                   }\n",
    "        training_set = pd.DataFrame.from_items(data.items(),\n",
    "                                               orient='index',\n",
    "                                              columns=columns)\n",
    "        a_perceptron._weights    = [0,1]\n",
    "        a_perceptron._threshold  = 1.0 \n",
    "        #since all the weight is on Feature B the prediction must \n",
    "        #equal the original classification\n",
    "        self.assertTrue(np.array_equal(\n",
    "                         a_perceptron.predict(\n",
    "                         training_set[['FeatureA', 'FeatureB']]),\n",
    "                         training_set['Classification']))\n",
    "        \n",
    "    def test_fit(self):\n",
    "        \n",
    "        a_perceptron = Perceptron()\n",
    "        columns = ['Classification', 'FeatureA', 'FeatureB']\n",
    "        data    = {'obs1': [ 1,0,1],\n",
    "                   'obs2': [ 1,0,1],\n",
    "                   'obs3': [-1,1,0],\n",
    "                   'obs4': [-1,1,0]\n",
    "                   }\n",
    "        training_set = pd.DataFrame.from_items(data.items(),\n",
    "                                               orient='index',\n",
    "                                              columns=columns)\n",
    "        \n",
    "        a_perceptron.fit(training_set[['FeatureA', 'FeatureB']].values, \n",
    "                         training_set['Classification'].values)\n",
    "        \n",
    "        self.assertEqual(a_perceptron.predict([0,10]),[1])\n",
    "        self.assertEqual(a_perceptron.predict([10,0]),[-1])\n",
    "        \n",
    "suite = unittest.TestLoader().loadTestsFromTestCase(TestPreceptron)\n",
    "unittest.TextTestRunner(verbosity=4).run(suite)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "perceptron        = Perceptron()\n",
    "#take a subset\n",
    "observed_features = iris_data[features]\n",
    "classifications   = iris_data['Classification']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "perceptron.fit(observed_features.values, classifications.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(-1)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Now we can use our perceptron to predict future flowers.\n",
    "#let's try for one flower\n",
    "perceptron.predict([5.1, 1.4])\n",
    "perceptron.predict([5.9,4.8])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
