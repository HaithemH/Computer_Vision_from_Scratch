{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <div align=\"center\">8.4 Parameter Initialization Strategies</div>\n",
    "---------------------------------------------------------------------\n",
    "\n",
    "you can Find me on Github:\n",
    "> ###### [ GitHub](https://github.com/lev1khachatryan)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some optimization algorithms are not iterative by nature and simply solve for a\n",
    "solution point. Other optimization algorithms are iterative by nature but, when\n",
    "applied to the right class of optimization problems, converge to acceptable solutions\n",
    "in an acceptable amount of time regardless of initialization. Deep learning training\n",
    "algorithms usually do not have either of these luxuries. Training algorithms for deep\n",
    "learning models are usually iterative in nature and thus require the user to specify\n",
    "some initial point from which to begin the iterations. Moreover, training deep\n",
    "models is a sufficiently difficult task that most algorithms are strongly affected by\n",
    "the choice of initialization. The initial point can determine whether the algorithm\n",
    "converges at all, with some initial points being so unstable that the algorithm\n",
    "encounters numerical difficulties and fails altogether. When learning does converge,\n",
    "the initial point can determine how quickly learning converges and whether it\n",
    "converges to a point with high or low cost. Also, points of comparable cost\n",
    "can have wildly varying generalization error, and the initial point can affect the\n",
    "generalization as well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modern initialization strategies are simple and heuristic. Designing improved\n",
    "initialization strategies is a difficult task because neural network optimization is\n",
    "not yet well understood. Most initialization strategies are based on achieving some\n",
    "nice properties when the network is initialized. However, we do not have a good\n",
    "understanding of which of these properties are preserved under which circumstances\n",
    "after learning begins to proceed. A further difficulty is that some initial points\n",
    "may be beneficial from the viewpoint of optimization but detrimental from the\n",
    "viewpoint of generalization. Our understanding of how the initial point affects\n",
    "generalization is especially primitive, offering little to no guidance for how to select\n",
    "the initial point."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perhaps the only property known with complete certainty is that the initial\n",
    "parameters need to “break symmetry” between different units. If two hidden\n",
    "units with the same activation function are connected to the same inputs, then\n",
    "these units must have different initial parameters. If they have the same initial\n",
    "parameters, then a deterministic learning algorithm applied to a deterministic cost\n",
    "and model will constantly update both of these units in the same way. Even if the\n",
    "model or training algorithm is capable of using stochasticity to compute different\n",
    "updates for different units (for example, if one trains with dropout), it is usually\n",
    "best to initialize each unit to compute a different function from all of the other\n",
    "units. This may help to make sure that no input patterns are lost in the null\n",
    "space of forward propagation and no gradient patterns are lost in the null space\n",
    "of back-propagation. The goal of having each unit compute a different function motivates random initialization of the parameters. We could explicitly search\n",
    "for a large set of basis functions that are all mutually different from each other,\n",
    "but this often incurs a noticeable computational cost. For example, if we have at\n",
    "most as many outputs as inputs, we could use Gram-Schmidt orthogonalization\n",
    "on an initial weight matrix, and be guaranteed that each unit computes a very\n",
    "different function from each other unit. Random initialization from a high-entropy\n",
    "distribution over a high-dimensional space is computationally cheaper and unlikely\n",
    "to assign any units to compute the same function as each other."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Typically, we set the biases for each unit to heuristically chosen constants, and\n",
    "initialize only the weights randomly. Extra parameters, for example, parameters\n",
    "encoding the conditional variance of a prediction, are usually set to heuristically\n",
    "chosen constants much like the biases are.\n",
    "\n",
    "We almost always initialize all the weights in the model to values drawn\n",
    "randomly from a Gaussian or uniform distribution. The choice of Gaussian\n",
    "or uniform distribution does not seem to matter very much, but has not been\n",
    "exhaustively studied. The scale of the initial distribution, however, does have a\n",
    "large effect on both the outcome of the optimization procedure and on the ability\n",
    "of the network to generalize."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Larger initial weights will yield a stronger symmetry breaking effect, helping\n",
    "to avoid redundant units. They also help to avoid losing signal during forward or\n",
    "back-propagation through the linear component of each layer—larger values in the\n",
    "matrix result in larger outputs of matrix multiplication. Initial weights that are\n",
    "too large may, however, result in exploding values during forward propagation or\n",
    "back-propagation. In recurrent networks, large weights can also result in chaos\n",
    "(such extreme sensitivity to small perturbations of the input that the behavior\n",
    "of the deterministic forward propagation procedure appears random). To some\n",
    "extent, the exploding gradient problem can be mitigated by gradient clipping\n",
    "(thresholding the values of the gradients before performing a gradient descent step).\n",
    "Large weights may also result in extreme values that cause the activation function\n",
    "to saturate, causing complete loss of gradient through saturated units. These\n",
    "competing factors determine the ideal initial scale of the weights."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The perspectives of regularization and optimization can give very different\n",
    "insights into how we should initialize a network. The optimization perspective\n",
    "suggests that the weights should be large enough to propagate information successfully, but some regularization concerns encourage making them smaller. The use\n",
    "of an optimization algorithm such as stochastic gradient descent that makes small\n",
    "incremental changes to the weights and tends to halt in areas that are nearer to\n",
    "the initial parameters (whether due to getting stuck in a region of low gradient, or due to triggering some early stopping criterion based on overfitting) expresses a\n",
    "prior that the final parameters should be close to the initial parameters. Recall\n",
    "from section 7.8 that gradient descent with early stopping is equivalent to weight\n",
    "decay for some models. In the general case, gradient descent with early stopping is\n",
    "not the same as weight decay, but does provide a loose analogy for thinking about\n",
    "the effect of initialization. We can think of initializing the parameters θ to θ0 as\n",
    "being similar to imposing a Gaussian prior p(θ) with mean θ0 . From this point\n",
    "of view, it makes sense to choose θ0 to be near 0. This prior says that it is more\n",
    "likely that units do not interact with each other than that they do interact. Units\n",
    "interact only if the likelihood term of the objective function expresses a strong\n",
    "preference for them to interact. On the other hand, if we initialize θ0 to large\n",
    "values, then our prior specifies which units should interact with each other, and\n",
    "how they should interact."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some heuristics are available for choosing the initial scale of the weights. One\n",
    "heuristic is to initialize the weights of a fully connected layer with m inputs and\n",
    "n outputs by sampling each weight from U (− 1/√m , 1/√m), while Glorot and Bengio\n",
    "(2010) suggest using the ***normalized initialization***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='asset/8_4/1.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This latter heuristic is designed to compromise between the goal of initializing\n",
    "all layers to have the same activation variance and the goal of initializing all\n",
    "layers to have the same gradient variance. ***The formula is derived using the\n",
    "assumption that the network consists only of a chain of matrix multiplications,\n",
    "with no nonlinearities.*** Real neural networks obviously violate this assumption,\n",
    "but many strategies designed for the linear model perform reasonably well on its\n",
    "nonlinear counterparts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saxe et al. (2013) recommend initializing to random orthogonal matrices, with\n",
    "a carefully chosen scaling or gain factor g that accounts for the nonlinearity applied\n",
    "at each layer. They derive specific values of the scaling factor for different types of\n",
    "nonlinear activation functions. This initialization scheme is also motivated by a\n",
    "model of a deep network as a sequence of matrix multiplies without nonlinearities.\n",
    "Under such a model, this initialization scheme guarantees that the total number of\n",
    "training iterations required to reach convergence is independent of depth."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Increasing the scaling factor g pushes the network toward the regime where\n",
    "activations increase in norm as they propagate forward through the network and\n",
    "gradients increase in norm as they propagate backward. Sussillo (2014) showed\n",
    "that setting the gain factor correctly is sufficient to train networks as deep as 1,000 layers, without needing to use orthogonal initializations. A key insight of\n",
    "this approach is that in feedforward networks, activations and gradients can grow\n",
    "or shrink on each step of forward or back-propagation, following a random walk\n",
    "behavior. This is because feedforward networks use a different weight matrix at\n",
    "each layer. If this random walk is tuned to preserve norms, then feedforward\n",
    "networks can mostly avoid the vanishing and exploding gradients problem that\n",
    "arises when the same weight matrix is used at each step, described in section 8.2.5."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unfortunately, these optimal criteria for initial weights often do not lead to\n",
    "optimal performance. This may be for three different reasons. First, we may\n",
    "be using the wrong criteria—it may not actually be beneficial to preserve the\n",
    "norm of a signal throughout the entire network. Second, the properties imposed\n",
    "at initialization may not persist after learning has begun to proceed. Third, the\n",
    "criteria might succeed at improving the speed of optimization but inadvertently\n",
    "increase generalization error. In practice, we usually need to treat the scale of the\n",
    "weights as a hyperparameter whose optimal value lies somewhere roughly near but\n",
    "not exactly equal to the theoretical predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One drawback to scaling rules that set all of the initial weights to have the\n",
    "same standard deviation, such as 1/√m, is that every individual weight becomes\n",
    "extremely small when the layers become large. Martens (2010) introduced an\n",
    "alternative initialization scheme called ***sparse initialization*** in which each unit is\n",
    "initialized to have exactly k non-zero weights. The idea is to keep the total amount\n",
    "of input to the unit independent from the number of inputs m without making the\n",
    "magnitude of individual weight elements shrink with m. Sparse initialization helps\n",
    "to achieve more diversity among the units at initialization time. However, it also\n",
    "imposes a very strong prior on the weights that are chosen to have large Gaussian\n",
    "values. Because it takes a long time for gradient descent to shrink “incorrect” large\n",
    "values, this initialization scheme can cause problems for units such as maxout units\n",
    "that have several filters that must be carefully coordinated with each other"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When computational resources allow it, it is usually a good idea to treat the\n",
    "initial scale of the weights for each layer as a hyperparameter, and to choose these\n",
    "scales using a hyperparameter search algorithm described in section 11.4.2, such\n",
    "as random search. The choice of whether to use dense or sparse initialization\n",
    "can also be made a hyperparameter. Alternately, one can manually search for\n",
    "the best initial scales. A good rule of thumb for choosing the initial scales is to\n",
    "look at the range or standard deviation of activations or gradients on a single\n",
    "minibatch of data. If the weights are too small, the range of activations across the\n",
    "minibatch will shrink as the activations propagate forward through the network.\n",
    "By repeatedly identifying the first layer with unacceptably small activations and increasing its weights, it is possible to eventually obtain a network with reasonable\n",
    "initial activations throughout. If learning is still too slow at this point, it can be\n",
    "useful to look at the range or standard deviation of the gradients as well as the\n",
    "activations. This procedure can in principle be automated and is generally less\n",
    "computationally costly than hyperparameter optimization based on validation set\n",
    "error because it is based on feedback from the behavior of the initial model on a\n",
    "single batch of data, rather than on feedback from a trained model on the validation\n",
    "set. While long used heuristically, this protocol has recently been specified more\n",
    "formally and studied by Mishkin and Matas (2015)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far we have focused on the initialization of the weights. Fortunately,\n",
    "initialization of other parameters is typically easier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The approach for setting the biases must be coordinated with the approach\n",
    "for settings the weights. Setting the biases to zero is compatible with most weight\n",
    "initialization schemes. There are a few situations where we may set some biases to\n",
    "non-zero values:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If a bias is for an output unit, then it is often beneficial to initialize the bias to\n",
    "obtain the right marginal statistics of the output. To do this, we assume that\n",
    "the initial weights are small enough that the output of the unit is determined\n",
    "only by the bias. This justifies setting the bias to the inverse of the activation\n",
    "function applied to the marginal statistics of the output in the training set.\n",
    "For example, if the output is a distribution over classes and this distribution\n",
    "is a highly skewed distribution with the marginal probability of class i given\n",
    "by element ci of some vector c, then we can set the bias vector b by solving\n",
    "the equation softmax(b) = c. This applies not only to classifiers but also to\n",
    "models we will encounter in Part III, such as autoencoders and Boltzmann\n",
    "machines. These models have layers whose output should resemble the input\n",
    "data x, and it can be very helpful to initialize the biases of such layers to\n",
    "match the marginal distribution over x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sometimes we may want to choose the bias to avoid causing too much\n",
    "saturation at initialization. For example, we may set the bias of a ReLU\n",
    "hidden unit to 0.1 rather than 0 to avoid saturating the ReLU at initialization.\n",
    "This approach is not compatible with weight initialization schemes that do\n",
    "not expect strong input from the biases though. For example, it is not\n",
    "recommended for use with random walk initialization (Sussillo, 2014)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another common type of parameter is a variance or precision parameter. For\n",
    "example, we can perform linear regression with a conditional variance estimate\n",
    "using the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='asset/8_4/2.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "where β is a precision parameter. We can usually initialize variance or precision\n",
    "parameters to 1 safely. Another approach is to assume the initial weights are close\n",
    "enough to zero that the biases may be set while ignoring the effect of the weights,\n",
    "then set the biases to produce the correct marginal mean of the output, and set\n",
    "the variance parameters to the marginal variance of the output in the training set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Besides these simple constant or random methods of initializing model parameters, it is possible to initialize model parameters using machine learning. A common\n",
    "strategy is to initialize a supervised model with\n",
    "the parameters learned by an unsupervised model trained on the same inputs.\n",
    "One can also perform supervised training on a related task. Even performing\n",
    "supervised training on an unrelated task can sometimes yield an initialization that\n",
    "offers faster convergence than a random initialization. Some of these initialization\n",
    "strategies may yield faster convergence and better generalization because they\n",
    "encode information about the distribution in the initial parameters of the model.\n",
    "Others apparently perform well primarily because they set the parameters to have\n",
    "the right scale or set different units to compute different functions from each other."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
