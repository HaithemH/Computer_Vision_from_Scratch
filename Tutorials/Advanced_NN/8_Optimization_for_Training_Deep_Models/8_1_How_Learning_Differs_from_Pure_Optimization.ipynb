{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <div align=\"center\">8.1 How Learning Differs from Pure Optimization</div>\n",
    "---------------------------------------------------------------------\n",
    "\n",
    "you can Find me on Github:\n",
    "> ###### [ GitHub](https://github.com/lev1khachatryan)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optimization algorithms used for training of deep models differ from traditional\n",
    "optimization algorithms in several ways. Machine learning usually acts indirectly.\n",
    "In most machine learning scenarios, we care about some performance measure\n",
    "P\n",
    ", that is defined with respect to the test set and may also be intractable. We\n",
    "therefore optimize P only indirectly. We reduce a different cost function J(θ) in\n",
    "the hope that doing so will improve P. This is in contrast to pure optimization,\n",
    "where minimizing J is a goal in and of itself. Optimization algorithms for training\n",
    "deep models also typically include some specialization on the specific structure of\n",
    "machine learning objective functions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Typically, the cost function can be written as an average over the training set,\n",
    "such as"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='asset/8_1/1.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "where L is the per-example loss function, f(x; θ) is the predicted output when\n",
    "the input is x, pˆdata is the empirical distribution. In the supervised learning case,\n",
    "y is the target output. Throughout this chapter, we develop the unregularized\n",
    "supervised case, where the arguments to L are f(x; θ) and y. However, it is trivial\n",
    "to extend this development, for example, to include θ or x as arguments, or to\n",
    "exclude y as arguments, in order to develop various forms of regularization or\n",
    "unsupervised learning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Equation 8.1 defines an objective function with respect to the training set. We\n",
    "would usually prefer to minimize the corresponding objective function where the\n",
    "expectation is taken across the data generating distribution pdata rather than just\n",
    "over the finite training set:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='asset/8_1/2.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <div align=\"center\">8.1.1 Empirical Risk Minimization</div>\n",
    "---------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal of a machine learning algorithm is to reduce the expected generalization\n",
    "error given by equation 8.2. This quantity is known as the risk. We emphasize here\n",
    "that the expectation is taken over the true underlying distribution pdata. If we knew\n",
    "the true distribution pdata(x, y), risk minimization would be an optimization task solvable by an optimization algorithm. However, when we do not know pdata(x, y)\n",
    "but only have a training set of samples, we have a machine learning problem.\n",
    "The simplest way to convert a machine learning problem back into an optimization problem is to minimize the expected loss on the training set. This\n",
    "means replacing the true distribution p(x, y) with the empirical distribution pˆ(x, y)\n",
    "defined by the training set. We now minimize the empirical risk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='asset/8_1/3.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "where m is the number of training examples.\n",
    "\n",
    "The training process based on minimizing this average training error is known\n",
    "as empirical risk minimization. In this setting, machine learning is still very\n",
    "similar to straightforward optimization. Rather than optimizing the risk directly,\n",
    "we optimize the empirical risk, and hope that the risk decreases significantly as\n",
    "well. A variety of theoretical results establish conditions under which the true risk\n",
    "can be expected to decrease by various amounts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, empirical risk minimization is prone to overfitting. Models with\n",
    "high capacity can simply memorize the training set. In many cases, empirical\n",
    "risk minimization is not really feasible. The most effective modern optimization\n",
    "algorithms are based on gradient descent, but many useful loss functions, such\n",
    "as 0-1 loss, have no useful derivatives (the derivative is either zero or undefined\n",
    "everywhere). These two problems mean that, in the context of deep learning, we\n",
    "rarely use empirical risk minimization. Instead, we must use a slightly different\n",
    "approach, in which the quantity that we actually optimize is even more different\n",
    "from the quantity that we truly want to optimize."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <div align=\"center\">8.1.2 Surrogate Loss Functions and Early Stopping</div>\n",
    "---------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sometimes, the loss function we actually care about (say classification error) is not\n",
    "one that can be optimized efficiently. For example, exactly minimizing expected 0-1\n",
    "loss is typically intractable (exponential in the input dimension), even for a linear\n",
    "classifier (Marcotte and Savard, 1992). In such situations, one typically optimizes\n",
    "a surrogate loss function instead, which acts as a proxy but has advantages.\n",
    "For example, the negative log-likelihood of the correct class is typically used as a\n",
    "surrogate for the 0-1 loss. The negative log-likelihood allows the model to estimate\n",
    "the conditional probability of the classes, given the input, and if the model can\n",
    "do that well, then it can pick the classes that yield the least classification error in\n",
    "expectation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In some cases, a surrogate loss function actually results in being able to learn\n",
    "more. For example, the test set 0-1 loss often continues to decrease for a long\n",
    "time after the training set 0-1 loss has reached zero, when training using the\n",
    "log-likelihood surrogate. This is because even when the expected 0-1 loss is zero,\n",
    "one can improve the robustness of the classifier by further pushing the classes apart\n",
    "from each other, obtaining a more confident and reliable classifier, thus extracting\n",
    "more information from the training data than would have been possible by simply\n",
    "minimizing the average 0-1 loss on the training set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A very important difference between optimization in general and optimization\n",
    "as we use it for training algorithms is that training algorithms do not usually halt\n",
    "at a local minimum. Instead, a machine learning algorithm usually minimizes\n",
    "a surrogate loss function but halts when a convergence criterion based on early\n",
    "stopping is satisfied. Typically the early stopping criterion is based\n",
    "on the true underlying loss function, such as 0-1 loss measured on a validation set,\n",
    "and is designed to cause the algorithm to halt whenever overfitting begins to occur.\n",
    "Training often halts while the surrogate loss function still has large derivatives,\n",
    "which is very different from the pure optimization setting, where an optimization\n",
    "algorithm is considered to have converged when the gradient becomes very small."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <div align=\"center\">8.1.3 Batch and Minibatch Algorithms</div>\n",
    "---------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One aspect of machine learning algorithms that separates them from general\n",
    "optimization algorithms is that the objective function usually decomposes as a sum\n",
    "over the training examples. Optimization algorithms for machine learning typically\n",
    "compute each update to the parameters based on an expected value of the cost\n",
    "function estimated using only a subset of the terms of the full cost function.\n",
    "\n",
    "For example, maximum likelihood estimation problems, when viewed in log\n",
    "space, decompose into a sum over each example:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='asset/8_1/4.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Maximizing this sum is equivalent to maximizing the expectation over the\n",
    "empirical distribution defined by the training set:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='asset/8_1/5.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most of the properties of the objective function J used by most of our optimization algorithms are also expectations over the training set. For example, the most commonly used property is the gradient:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='asset/8_1/6.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Computing this expectation exactly is very expensive because it requires\n",
    "evaluating the model on every example in the entire dataset. In practice, we can\n",
    "compute these expectations by randomly sampling a small number of examples\n",
    "from the dataset, then taking the average over only those examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall that the standard error of the mean estimated from n\n",
    "samples is given by σ/√n, where σ is the true standard deviation of the value of\n",
    "the samples. The denominator of √n shows that there are less than linear returns\n",
    "to using more examples to estimate the gradient. Compare two hypothetical\n",
    "estimates of the gradient, one based on 100 examples and another based on 10,000\n",
    "examples. The latter requires 100 times more computation than the former, but\n",
    "reduces the standard error of the mean only by a factor of 10. Most optimization\n",
    "algorithms converge much faster (in terms of total computation, not in terms of\n",
    "number of updates) if they are allowed to rapidly compute approximate estimates\n",
    "of the gradient rather than slowly computing the exact gradient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another consideration motivating statistical estimation of the gradient from a\n",
    "small number of samples is redundancy in the training set. In the worst case, all\n",
    "m samples in the training set could be identical copies of each other. A samplingbased estimate of the gradient could compute the correct gradient with a single\n",
    "sample, using m times less computation than the naive approach. In practice, we\n",
    "are unlikely to truly encounter this worst-case situation, but we may find large\n",
    "numbers of examples that all make very similar contributions to the gradient."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optimization algorithms that use the entire training set are called ***batch or\n",
    "deterministic gradient methods***, because they process all of the training examples\n",
    "simultaneously in a large batch. This terminology can be somewhat confusing\n",
    "because the word “batch” is also often used to describe the minibatch used by\n",
    "minibatch stochastic gradient descent. Typically the term “batch gradient descent”\n",
    "implies the use of the full training set, while the use of the term “batch” to describe\n",
    "a group of examples does not. For example, it is very common to use the term\n",
    "“batch size” to describe the size of a minibatch."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optimization algorithms that use only a single example at a time are sometimes\n",
    "called stochastic or sometimes online methods. The term online is usually\n",
    "reserved for the case where the examples are drawn from a stream of continually\n",
    "created examples rather than from a fixed-size training set over which several\n",
    "passes are made.\n",
    "\n",
    "Most algorithms used for deep learning fall somewhere in between, using more than one but less than all of the training examples. These were traditionally called\n",
    "minibatch or minibatch stochastic methods and it is now common to simply\n",
    "call them ***stochastic methods***."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The canonical example of a stochastic method is stochastic gradient descent,\n",
    "presented in detail in section 8.3.1.\n",
    "\n",
    "Minibatch sizes are generally driven by the following factors:\n",
    "\n",
    "*  Larger batches provide a more accurate estimate of the gradient, but with less than linear returns.\n",
    "\n",
    "\n",
    "* Multicore architectures are usually underutilized by extremely small batches. This motivates using some absolute minimum batch size, below which there is no reduction in the time to process a minibatch.\n",
    "\n",
    "\n",
    "* If all examples in the batch are to be processed in parallel (as is typically the case), then the amount of memory scales with the batch size. For many hardware setups this is the limiting factor in batch size.\n",
    "\n",
    "\n",
    "* Some kinds of hardware achieve better runtime with specific sizes of arrays. Especially when using GPUs, it is common for power of 2 batch sizes to offer better runtime. Typical power of 2 batch sizes range from 32 to 256, with 16 sometimes being attempted for large models.\n",
    "\n",
    "\n",
    "*  Small batches can offer a regularizing effect (Wilson and Martinez, 2003), perhaps due to the noise they add to the learning process. Generalization error is often best for a batch size of 1. Training with such a small batch size might require a small learning rate to maintain stability due to the high variance in the estimate of the gradient. The total runtime can be very high due to the need to make more steps, both because of the reduced learning rate and because it takes more steps to observe the entire training set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Different kinds of algorithms use different kinds of information from the minibatch in different ways. Some algorithms are more sensitive to sampling error than\n",
    "others, either because they use information that is difficult to estimate accurately\n",
    "with few samples, or because they use information in ways that amplify sampling\n",
    "errors more. Methods that compute updates based only on the gradient g are\n",
    "usually relatively robust and can handle smaller batch sizes like 100. Second-order\n",
    "methods, which use also the Hessian matrix H and compute updates such as\n",
    "$H^{−1}g$, typically require much larger batch sizes like 10,000. These large batch\n",
    "sizes are required to minimize fluctuations in the estimates of $H^{−1}g$. Suppose\n",
    "that H is estimated perfectly but has a poor condition number. Multiplication by H or its inverse amplifies pre-existing errors, in this case, estimation errors in g.\n",
    "Very small changes in the estimate of g can thus cause large changes in the update\n",
    "$H^{−1}g$, even if H were estimated perfectly. Of course, H will be estimated only\n",
    "approximately, so the update $H^{−1}g$ will contain even more error than we would\n",
    "predict from applying a poorly conditioned operation to the estimate of g."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is also crucial that the minibatches be selected randomly. Computing an\n",
    "unbiased estimate of the expected gradient from a set of samples requires that those\n",
    "samples be independent. We also wish for two subsequent gradient estimates to be\n",
    "independent from each other, so two subsequent minibatches of examples should\n",
    "also be independent from each other. Many datasets are most naturally arranged\n",
    "in a way where successive examples are highly correlated. For example, we might\n",
    "have a dataset of medical data with a long list of blood sample test results. This\n",
    "list might be arranged so that first we have five blood samples taken at different\n",
    "times from the first patient, then we have three blood samples taken from the\n",
    "second patient, then the blood samples from the third patient, and so on. If we\n",
    "were to draw examples in order from this list, then each of our minibatches would\n",
    "be extremely biased, because it would represent primarily one patient out of the\n",
    "many patients in the dataset. In cases such as these where the order of the dataset\n",
    "holds some significance, it is necessary to shuffle the examples before selecting\n",
    "minibatches. For very large datasets, for example datasets containing billions of\n",
    "examples in a data center, it can be impractical to sample examples truly uniformly\n",
    "at random every time we want to construct a minibatch. Fortunately, in practice\n",
    "it is usually sufficient to shuffle the order of the dataset once and then store it in\n",
    "shuffled fashion. This will impose a fixed set of possible minibatches of consecutive\n",
    "examples that all models trained thereafter will use, and each individual model\n",
    "will be forced to reuse this ordering every time it passes through the training\n",
    "data. However, this deviation from true random selection does not seem to have a\n",
    "significant detrimental effect. Failing to ever shuffle the examples in any way can\n",
    "seriously reduce the effectiveness of the algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Many optimization problems in machine learning decompose over examples\n",
    "well enough that we can compute entire separate updates over different examples\n",
    "in parallel. In other words, we can compute the update that minimizes J(X) for\n",
    "one minibatch of examples X at the same time that we compute the update for\n",
    "several other minibatches."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An interesting motivation for minibatch stochastic gradient descent is that it\n",
    "follows the gradient of the true generalization error (equation 8.2) so long as no\n",
    "examples are repeated. Most implementations of minibatch stochastic gradient descent shuffle the dataset once and then pass through it multiple times. On the\n",
    "first pass, each minibatch is used to compute an unbiased estimate of the true\n",
    "generalization error. On the second pass, the estimate becomes biased because it is\n",
    "formed by re-sampling values that have already been used, rather than obtaining\n",
    "new fair samples from the data generating distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The fact that stochastic gradient descent minimizes generalization error is\n",
    "easiest to see in the online learning case, where examples or minibatches are drawn\n",
    "from a stream of data. In other words, instead of receiving a fixed-size training\n",
    "set, the learner is similar to a living being who sees a new example at each instant,\n",
    "with every example (x, y) coming from the data generating distribution $p_{data(x, y)}$.\n",
    "In this scenario, examples are never repeated; every experience is a fair sample\n",
    "from $p_{data}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The equivalence is easiest to derive when both x and y are discrete. In this\n",
    "case, the generalization error (equation 8.2) can be written as a sum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='asset/8_1/7.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "with the exact gradient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='asset/8_1/8.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have already seen the same fact demonstrated for the log-likelihood in equation 8.5 and equation 8.6; we observe now that this holds for other functions L\n",
    "besides the likelihood. A similar result can be derived when x and y are continuous,\n",
    "under mild assumptions regarding pdata and L."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hence, we can obtain an unbiased estimator of the exact gradient of the\n",
    "generalization error by sampling a minibatch of examples {x(1), . . . x(m)} with corresponding targets y(i) from the data generating distribution pdata, and computing\n",
    "the gradient of the loss with respect to the parameters for that minibatch:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='asset/8_1/9.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Updating θ in the direction of gˆ performs SGD on the generalization error.\n",
    "\n",
    "Of course, this interpretation only applies when examples are not reused.\n",
    "Nonetheless, it is usually best to make several passes through the training set,\n",
    "unless the training set is extremely large. When multiple such epochs are used,\n",
    "only the first epoch follows the unbiased gradient of the generalization error, but of course, the additional epochs usually provide enough benefit due to decreased\n",
    "training error to offset the harm they cause by increasing the gap between training\n",
    "error and test error."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With some datasets growing rapidly in size, faster than computing power, it\n",
    "is becoming more common for machine learning applications to use each training\n",
    "example only once or even to make an incomplete pass through the training\n",
    "set. When using an extremely large training set, overfitting is not an issue, so\n",
    "underfitting and computational efficiency become the predominant concerns."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
