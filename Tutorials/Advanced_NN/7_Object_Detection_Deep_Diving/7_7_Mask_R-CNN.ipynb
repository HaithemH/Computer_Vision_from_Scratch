{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <div align=\"center\">Mask R-CNN</div>\n",
    "---------------------------------------------------------------------\n",
    "\n",
    "you can Find me on Github:\n",
    "> ###### [ GitHub](https://github.com/lev1khachatryan)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a conceptually simple, flexible, and general\n",
    "framework for object ***instance segmentation***. Our approach\n",
    "efficiently detects objects in an image while simultaneously\n",
    "generating a high-quality segmentation mask for each instance. The method, called Mask R-CNN, extends Faster\n",
    "R-CNN by adding a branch for predicting an object mask in\n",
    "parallel with the existing branch for bounding box recognition. Mask R-CNN is simple to train and adds only a small\n",
    "overhead to Faster R-CNN, running at 5 fps. Moreover,\n",
    "Mask R-CNN is easy to generalize to other tasks, e.g., allowing us to estimate human poses in the same framework."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <div align=\"center\">1. Introduction</div>\n",
    "---------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The vision community has rapidly improved object detection and semantic segmentation results over a short period of time. In large part, these advances have been driven\n",
    "by powerful baseline systems, such as the Fast/Faster RCNN and Fully Convolutional Network (FCN)\n",
    "frameworks for object detection and semantic segmentation, respectively. These methods are conceptually intuitive\n",
    "and offer flexibility and robustness, together with fast training and inference time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instance segmentation is challenging because it requires\n",
    "the correct detection of all objects in an image while also\n",
    "precisely segmenting each instance. It therefore combines\n",
    "elements from the classical computer vision tasks of object detection, where the goal is to classify individual objects and localize each using a bounding box, and semantic segmentation, where the goal is to classify each pixel into\n",
    "a fixed set of categories without differentiating object instances."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As I said, method called Mask R-CNN, extends Faster R-CNN by adding a branch for predicting segmentation masks\n",
    "on each Region of Interest (RoI), in parallel with the existing branch for classification and bounding box regression (Figure 1). The mask branch is a small FCN applied\n",
    "to each RoI, predicting a segmentation mask in a pixel-to-pixel manner. Mask R-CNN is simple to implement and\n",
    "train given the Faster R-CNN framework, which facilitates\n",
    "a wide range of flexible architecture designs. Additionally,\n",
    "the mask branch only adds a small computational overhead,\n",
    "enabling a fast system and rapid experimentation․"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='asset/7_7/1.png'>\n",
    "<div align=\"center\">Figure 1. The Mask R-CNN framework for instance segmentation.</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In principle ***Mask R-CNN is an intuitive extension of\n",
    "Faster R-CNN***, yet constructing the mask branch properly\n",
    "is critical for good results. Most importantly, Faster RCNN was not designed for pixel-to-pixel alignment between network inputs and outputs. This is most evident in\n",
    "how RoIPool, the de facto core operation for attending to instances, performs coarse spatial quantization\n",
    "for feature extraction. To fix the misalignment, Mask R-CNN propose a simple, quantization-free layer, called ***RoIAlign***, that\n",
    "faithfully preserves exact spatial locations. Despite being a seemingly minor change, RoIAlign has a large impact: it\n",
    "improves mask accuracy by relative 10% to 50%, showing\n",
    "bigger gains under stricter localization metrics. Second, model predicts a binary mask for each class independently, without\n",
    "competition among classes, and rely on the network’s RoI\n",
    "classification branch to predict the category. In contrast,\n",
    "FCNs usually perform per-pixel multi-class categorization,\n",
    "which couples segmentation and classification, and based\n",
    "on our experiments works poorly for instance segmentation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <div align=\"center\">2. Mask R-CNN</div>\n",
    "---------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If faster R-CNN has two outputs for each candidate object, a class label and a\n",
    "bounding-box offset; Mask R-CNN adds a third branch that outputs the object mask. Mask R-CNN is thus a natural and intuitive idea. But the additional mask output is distinct from\n",
    "the class and box outputs, requiring extraction of much finer\n",
    "spatial layout of an object. Next, we introduce the key elements of Mask R-CNN, including pixel-to-pixel alignment,\n",
    "which is the main missing piece of Fast/Faster R-CNN."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mask R-CNN adopts the same two-stage\n",
    "procedure of faster R-CNN, with an identical first stage (which is RPN). In\n",
    "the second stage, in parallel to predicting the class and box\n",
    "offset, Mask R-CNN also outputs a binary mask for each\n",
    "RoI. This is in contrast to most recent systems, where classification depends on mask predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Formally, during training, we define a multi-task loss on each sampled RoI as $L = L_{cls} + L_{box} + L_{mask}$. The classification loss $L_{cls}$ and bounding-box loss $L_{box}$ are identical as those defined in Faster R-CNN. The mask branch has a $Km^2$\n",
    "-\n",
    "dimensional output for each RoI, which encodes K binary\n",
    "masks of resolution m × m, one for each of the K classes.\n",
    "To this we apply a per-pixel sigmoid, and define $L_{mask}$ as\n",
    "the average binary cross-entropy loss. For an RoI associated\n",
    "with ground-truth class k, $L_{mask}$ is only defined on the k-th\n",
    "mask (other mask outputs do not contribute to the loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The definition of $L_{mask}$ allows the network to generate\n",
    "masks for every class without competition among classes;\n",
    "we rely on the dedicated classification branch to predict the class label used to select the output mask. This decouples\n",
    "mask and class prediction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <div align=\"center\">2.1 Mask Representation:CNN</div>\n",
    "---------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A mask encodes an input object’s\n",
    "spatial layout. Thus, unlike class labels or box offsets\n",
    "that are inevitably collapsed into short output vectors by\n",
    "fully-connected (fc) layers, extracting the spatial structure\n",
    "of masks can be addressed naturally by the pixel-to-pixel\n",
    "correspondence provided by convolutions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Specifically, we predict an m × m mask from each RoI\n",
    "using an FCN. This allows each layer in the mask\n",
    "branch to maintain the explicit m × m object spatial layout without collapsing it into a vector representation that\n",
    "lacks spatial dimensions. Unlike previous methods that resort to fc layers for mask prediction, our fully\n",
    "convolutional representation requires fewer parameters, and\n",
    "is more accurate as demonstrated by experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <div align=\"center\">Summing it all up</div>\n",
    "---------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So the Mask R-CNN extends Faster R-CNN to pixel-level image segmentation. The key point is to decouple the classification and the pixel-level mask prediction tasks. Based on the framework of Faster R-CNN, it added a third branch for predicting an object mask in parallel with the existing branches for classification and localization. The mask branch is a small fully-connected network applied to each RoI, predicting a segmentation mask in a pixel-to-pixel manner."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='asset/7_7/2.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because pixel-level segmentation requires much more fine-grained alignment than bounding boxes, mask R-CNN improves the RoI pooling layer (named ***“RoIAlign layer”***) so that RoI can be better and more precisely mapped to the regions of the original image."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='asset/7_7/3.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ***RoIAlign*** layer is designed to fix the location misalignment caused by quantization in the RoI pooling. RoIAlign removes the hash quantization, for example, by using x/16 instead of [x/16], so that the extracted features can be properly aligned with the input pixels. Bilinear interpolation is used for computing the floating-point location values in the input."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='asset/7_7/4.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A region of interest is mapped accurately from the original image onto the feature map without rounding up to integers. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <div align=\"center\">Loss Function</div>\n",
    "---------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='asset/7_7/5.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <div align=\"center\">Summary of Models in the R-CNN family</div>\n",
    "---------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='asset/7_7/6.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
