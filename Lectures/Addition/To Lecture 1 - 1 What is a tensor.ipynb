{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <div align=\"center\">What is a Tensor</div>\n",
    "---------------------------------------------------------------------\n",
    "\n",
    "you can Find me on Github:\n",
    "> ###### [ GitHub](https://github.com/lev1khachatryan)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Tensors are not generalizations of vectors***. It’s very slightly more understandable to say that tensors are generalizations of matrices, in the same way that it is slightly more accurate to say “vanilla ice cream is a generalization of chocolate ice cream” than it is to say that “vanilla ice cream is a generalization of dessert”, closer, but still false. Vanilla and Chocolate are both ice cream, but chocolate ice cream is not a type of vanilla ice cream, and “dessert” certainly isn’t a type of vanilla ice cream. In fact, technically, ***vectors are generalizations of tensors.*** What we generally think of as vectors are geometrical points in space, and we normally represent them as an array of numbers. That array of numbers is what people are referring to when they say \"Tensors are generalizations of vectors\", but really, even this adjusted claim is fundamentally false and extremely misleading.\n",
    "\n",
    "At first let's define what is a vector."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definition of a vector space"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The set ***V*** is a vector space with respect to the operations + (which is any operation that maps two elements of the space to another element of the space, not necessarily addition) and * (which is any operation that maps an element in the space and a scalar to another element in the space, not necessarily multiplication) if and only if, for every $x,y,z ∈ V$ and $a,b ∈ R$\n",
    "\n",
    "* \\+ is commutative, that is x+y=y+x\n",
    "\n",
    "\n",
    "* \\+ is associative, that is (x+y)+z=x+(y+z)\n",
    "\n",
    "\n",
    "* There exists an identity element in the space, that is there exists an element 0 such that x+0=x\n",
    "\n",
    "\n",
    "* Every element has an inverse, that is for every element x there exists an element −x such that x+−x=0\n",
    "\n",
    "\n",
    "* \\* is associative, that is a(b∗x)=(ab)∗x\n",
    "\n",
    "\n",
    "* There is scalar distributivity over +, that is a∗(x+y)=a∗x+a∗y\n",
    "\n",
    "\n",
    "* There is vector distributivity over scalar addition, that is (a+b)∗x=a∗x+b∗x\n",
    "\n",
    "\n",
    "* And finally, 1∗x=x (it can be obtained from above mentioned 7 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***A vector is defined as a member of such a space***. Notice how nothing here is explicitly stated to be numerical. We could be talking about colors, or elephants, or glasses of milk; as long as we meaningfully define these two operations, anything can be a vector. The special case of vectors that we usually think about in physics and geometry satisfy this definition ( i.e. points in space or “arrows”). Thus, “arrows” are special cases of vectors. More formally, every “arrow” v represents the line segment from 0, \"the origin\", which is the identity element of the vector space, to some other point in space. In this view, you can construct a vector space of “arrows” by first picking a point in space, and taking the set of all line segments from that point. (From now on, I will use the term “arrows” to formally distinguish between formal vectors and the type of vectors that have “magnitude and direction”.)\n",
    "\n",
    "Okay, so anyone trying to understand tensors probably already knows this stuff.\n",
    "\n",
    "But here is something you may not have heard about before if you are learning about tensors. When we define a vector space like this, we generally find that it is natural to define an operation that gives us lengths and angles. ***A vector space with lengths and angles is called an inner product space.***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definition of a Inner product space"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An inner product space is a vector space V with an additional operation ***⋅*** such that, for all x,y,z ∈ V\n",
    "\n",
    "* x⋅y ∈ R\n",
    "\n",
    "\n",
    "* x⋅x ≥ 0\n",
    "\n",
    "\n",
    "* x⋅x=0 ⟺ x=0\n",
    "\n",
    "\n",
    "* x⋅(ay)=a(x⋅y)\n",
    "\n",
    "\n",
    "* x⋅y=y⋅x\n",
    "\n",
    "\n",
    "* x⋅(y+z)=x⋅y+x⋅z\n",
    "\n",
    "We define the length of a vector x in an inner product space to be $||x|| = \\sqrt[2]{x⋅x}$ , and the angle between two vectors x,y to be $arccos(\\frac{x⋅y}{||x||||y||}).$\n",
    "\n",
    "This is the equivalent of the dot product, which is defined to be $||x||||y||cos(θ)$, but note that this is not defined in terms of any sort of \"components\" of the vector, there are no arrays of numbers mentioned. I.e. the dot product is a geometrical operation.\n",
    "\n",
    "So I have secretly given you your first glimpse at a tensor. Where was it? Was it x? Was it y? Was it V? Was it the glass of milk???\n",
    "\n",
    "It was none of these things; ***it was the operation itself . The dot product itself is an example of a tensor.***\n",
    "\n",
    "Well, again, ***tensors aren’t generalizations of vectors at all. Vectors, as we defined them above, are generalizations of tensors. And tensors aren’t technically generalizations of matrices. But tensors can certainly be thought of as kind of the same sort of object as a matrix.***\n",
    "\n",
    "There are two things that tensors and matrices have in common. The first, and most important thing, is that they are both n-linear maps. This is why tensors are almost generalizations of matrices. The second, and more misleading, thing is that they can be represented as a 2d array of numbers. This second thing is a huge, and I mean HUGE red herring, and has undoubtedly caused an innumerable number of people to be confused.\n",
    "\n",
    "*Let’s tackle the concept of bilinear maps, and then we can use that knowledge of bilinear maps to help us tackle the concept of representing rank 2 tensors as 2d arrays.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bilinear maps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dot product is what the cool kids like to call a bilinear map. This just means that the dot product has the following properties:\n",
    "\n",
    "* x⋅(y+z)=x⋅y+x⋅z\n",
    "\n",
    "\n",
    "* (y+z)⋅x=y⋅x+z⋅x\n",
    "\n",
    "\n",
    "* x⋅(ay)=a(x⋅y)\n",
    "\n",
    "Why is this important? Well if we represent the vector x as $x=x_{1}i+x_{2}j$, and we represent the vector $y=y_{1}i+y_{2}j$, then because ⋅ is linear, the following is true: $x⋅y=y_{1} x_{1} i⋅i + y_{2} x_{2} j⋅j + (x_{1} y_{2} + x_{2} y_{1})i⋅j$\n",
    "\n",
    "This means if we know the values of i⋅i, j⋅j, and i⋅j, then we have completely defined the operation ⋅. In other words, knowing just these 3 values allows us to calculate the value of x⋅y for any x and y.\n",
    "\n",
    "Now we can describe how ⋅ might be represented as a 2d array. If ⋅ is the standard cartesian dot product that you learned about on the first day of your linear algebra or physics class, and i and j are both the standard cartesian unit vectors, then i⋅i=1, j⋅j=1, and j⋅i=i⋅j=0.\n",
    "\n",
    "To represent this tensor ⋅ as a 2d array, we would create a table holding these values, i.e.\n",
    "\n",
    "\\begin{bmatrix}\n",
    "       ⋅ & i & j \\\\[0.3em]\n",
    "       i & 1 & 0 \\\\[0.3em]\n",
    "       j & 0 & 1\n",
    "     \\end{bmatrix}\n",
    "     \n",
    "Or, more compactly\n",
    "\n",
    "\\begin{bmatrix}\n",
    "       1 & 0 \\\\[0.3em]\n",
    "       0 & 1\n",
    "     \\end{bmatrix}\n",
    "     \n",
    "DO NOT LET THIS SIMILARITY TO THE SIMILAR MATRIX NOTATION FOOL YOU. Multiplying this by a vector will clearly give the wrong answer for many reasons, the most important of which is that the dot product produces a scalar quantity, a matrix produces a vector quantity. This notation is simply a way of neatly writing what the dot product represents, it is not a way of making the dot product into a matrix.\n",
    "\n",
    "If we become more general, then we can take arbitrary values for these dot products i⋅i=a, j⋅j=b, and j⋅i=i⋅j=c.\n",
    "\n",
    "Which would be represented as\n",
    "\n",
    "\\begin{bmatrix}\n",
    "       a & c \\\\[0.3em]\n",
    "       c & b\n",
    "     \\end{bmatrix}\n",
    "     \n",
    "***A tensor defined in this way is called the metric tensor. The reason it is called that, and the reason it is so important in general relativity, is that just by changing the values we can change the definition of lengths and angles*** (remember that inner product spaces define length and angles in terms of ⋅), and we can enumerate over all possible definitions of lengths and angles. We call this a rank 2 tensor because it is a 2d array (i.e. it looks like a square), if we had a 3x3 tensor, such as a metric tensor for 3 dimensional space it would still be an example of a rank 2 tensor.\n",
    "\n",
    "\\begin{bmatrix}\n",
    "       a & s & d \\\\[0.3em]\n",
    "       f & g & h \\\\[0.3em]\n",
    "       z & x & b\n",
    "     \\end{bmatrix}\n",
    "     \n",
    "(Note: the table is symmetric along the diagonal only because the metric tensor is commutative. A general tensor does not have to be commutative and thus its representation does not have to be symmetric.)\n",
    "\n",
    "To get a rank 3 tensor, we would create a cube-like table of values as opposed to a square-like one (I can’t do this in latex so you’ll have to imagine it). A rank 3 tensor would be a trilinear map. A trilinear map m takes 3 vectors from a vector space V, and can be defined in terms of the values it takes when its arguments are the basis vectors of V. E.g. if V has two basis vectors i and j, then m can be defined by defining the values of m(i,i,i), m(i,i,j), m(i,j,i), m(i,j,j), m(j,i,i), m(j,i,j), m(j,j,i), and m(j,j,j) in a 3d array.\n",
    "\n",
    "\n",
    "A rank 4 tensor would be a 4-linear, A.K.A quadrlinear map that would take 4 arguments, and thus be represented as a 4 dimensional array etc.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Why do people think tensors are generalizations of vectors?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So now we come to why people think tensors are generalizations of vectors. Its because, if we take a function $f(y)=x⋅y$, then f, being the linear scallawag it is, can be defined with only 2 values. $f(y)=y_{1}f(i)+y_{2}f(j)$, so knowing the values of f(i)and f(j) completely define f. And therefore, f is a rank 1 tensor, i.e. a multilinear map with one argument. This would be represented as a 1d array, very much like the common notion of a vector. Furthermore, these values completely define x as well. If ⋅ is specifically the cartesian metric tensor, then the values of the representation of x and the values of the representation of f are exactly the same. This is why people think tensors are generalizations of vectors.\n",
    "\n",
    "But if ⋅ is given different values, then the representation of x and the representation of f will have different values. ***Vectors by themselves are not linear maps, they can just be thought of as linear maps***. In order for them to actually be linear maps, they need to be combined with some sort of linear operator such as ⋅.\n",
    "\n",
    "So here is the definition: ***A tensor is any multilinear map from a vector space to a scalar field***. (Note: A multilinear map is just a generalization of linear and bilinear maps to maps that have more than 2 arguments. I.e. any map which is distributive over addition and scalar multiplication. Linear maps are considered a type of multilinear map)\n",
    "\n",
    "This definition as a multilinear maps is another reason people think tensors are generalization of matrices, because matrices are linear maps just like tensors. But the distinction is that matrices take a vector space to itself, while tensors take a vector space to a scalar field. So a matrix is not strictly speaking a tensor."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
