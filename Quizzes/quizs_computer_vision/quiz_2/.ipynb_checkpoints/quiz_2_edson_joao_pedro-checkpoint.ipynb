{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quiz 2\n",
    "\n",
    "#### **Nomes:**  Edson Roteia Araujo Junior e JoÃ£o Pedro Moreira Ferreira"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First estimation - Manual Calculation from a Single Image###\n",
    "\n",
    "- Configuration for naive estimation:\n",
    "\n",
    "![](./imgs/chess.jpg.png)\n",
    "\n",
    "- Size in pixel of the target (that we used as our \"book\"):\n",
    "   - width: 870px\n",
    "   - heigth: 696px\n",
    "   \n",
    "\n",
    "From the equations:\n",
    "$f_x = \\frac{d_x}{d_X} d_z, f_y = \\frac{d_y}{d_Y} d_z $ (1)\n",
    "\n",
    "We have:\n",
    "$f_x = \\frac{870}{294} 1200, f_y = \\frac{696}{234}1200$\n",
    "\n",
    "So:\n",
    "$f_x = 3551.02, f_y = 3569.23$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Second estimation - Using MATLAB App (Camera Calibrator)###\n",
    "\n",
    "- Input images to estimate camera parameters\n",
    "\n",
    "![](./imgs/input_matlab.png)\n",
    "\n",
    "\n",
    "- Camera Calibrator App for MATLAB\n",
    "\n",
    "![](./imgs/app.png)\n",
    "\n",
    "\n",
    "- Camera parameters estimate by the MATLAB App\n",
    "\n",
    "![](./imgs/matlab_5.png)\n",
    "\n",
    "The Camera Calibrator MATLAB App Estimate the follow parameters:\n",
    "\n",
    "![](./imgs/extrinsic.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Last Estimation - Using SVD in Python (Following the algorithm by Trucco and Verri)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Measure the 3-D coordinates of each vector of the $n$ squares on the calibration pattern in the world reference frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "##read images\n",
    "images_name = ['./imgs/target.jpg']\n",
    "images = []\n",
    "for img_name in images_name:\n",
    "    img = cv2.imread(img_name)\n",
    "    images.append(img)\n",
    "\n",
    "worldpoints = ([27.2,0,80],\n",
    "            [47.2,0,80],\n",
    "            [67.2,0,80],\n",
    "            [27.2,0,60],\n",
    "            [47.2,0,60],\n",
    "            [67.2,0,60],\n",
    "            [27.2,0,40],\n",
    "            [47.2,0,40],\n",
    "            [67.2,0,40],\n",
    "            [27.2,0,20],\n",
    "            [47.2,0,20],\n",
    "            [67.2,0,20],\n",
    "            [27.2,0,0],\n",
    "            [47.2,0,0],\n",
    "            [67.2,0,0],\n",
    "            [0,24.5,80],\n",
    "            [0,44.5,80],\n",
    "            [0,64.5,80],\n",
    "            [0,24.5,60],\n",
    "            [0,44.5,60],\n",
    "            [0,64.5,60],\n",
    "            [0,24.5,40],\n",
    "            [0,44.5,40],\n",
    "            [0,64.5,40],\n",
    "            [0,24.5,20],\n",
    "            [0,44.5,20],\n",
    "            [0,64.5,20]\n",
    "              )\n",
    "\n",
    "worldpoints = np.asarray(worldpoints)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our calibration target:\n",
    "\n",
    "![](./imgs/target.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Find the coordinates in the image reference frame of each of the $N$ vertices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgpoints = ([2270.7, 881.3],\n",
    "            [2404.7, 908.7],\n",
    "            [2531.3, 930],\n",
    "            [2283.3, 1060],\n",
    "            [2413.3, 1080],\n",
    "            [2542.7, 1100],\n",
    "            [2292, 1243.3],\n",
    "            [2425.3, 1256.7],\n",
    "            [2552, 1270],\n",
    "            [2306.7, 1427.3],\n",
    "            [2436.7, 1434.7],\n",
    "            [2566.7, 1440.7],\n",
    "            [2320, 1616],\n",
    "            [2458.7, 1616.7],\n",
    "            [2579.3, 1616.7],\n",
    "            [1938.7, 906],\n",
    "            [1828, 945],\n",
    "            [1712.7, 986.7],\n",
    "            [1952.7, 1082],\n",
    "            [1834, 1120.7],\n",
    "            [1728.7, 1152],\n",
    "            [1954.7, 1266.7],\n",
    "            [1848, 1296.7],\n",
    "            [1736, 1328],\n",
    "            [1965.3, 1451.3],\n",
    "            [1847.3, 1476],\n",
    "            [1738.7, 1498]\n",
    "            )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Having the $N$ correspondences between image and world points, compute the SVD of $A$ (6.8). The solution is the column of $V$ corresponding to the smallest singular value of $A$.\n",
    "![](./imgs/trucco6.8.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create A matrix\n",
    "A = []\n",
    "for worldpoint,imagepoint in zip(worldpoints,imgpoints):\n",
    "    A_line = []\n",
    "    A_line.append(imagepoint[0] * worldpoint[0])\n",
    "    A_line.append(imagepoint[0] * worldpoint[1])\n",
    "    A_line.append(imagepoint[0] * worldpoint[2])\n",
    "    A_line.append(imagepoint[0])\n",
    "    A_line.append(-imagepoint[1] * worldpoint[0])\n",
    "    A_line.append(-imagepoint[1] * worldpoint[1])\n",
    "    A_line.append(-imagepoint[1] * worldpoint[2])\n",
    "    A_line.append(-imagepoint[1])\n",
    "    A.append(A_line)\n",
    "\n",
    "A = np.asarray(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#run SVD\n",
    "U, D, V = np.linalg.svd(A, full_matrices=True)\n",
    "minSingValue = np.argmin(D)\n",
    "V_selected = V[minSingValue]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate gamma and alfa\n",
    "gamma = (V_selected[0] ** 2 + V_selected[1] ** 2 + V_selected[2] ** 2 ) ** (1/2)\n",
    "alfa = ((V_selected[4] ** 2 + V_selected[5] ** 2 + V_selected[6] ** 2 ) ** (1/2))/gamma"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. Recover the first two rows of $R$ and the two first components of $T$ from (6.9)\n",
    "![](./imgs/trucco6.9.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate two firts rows of r and two firts elements of t\n",
    "r = np.ones(shape=(3,3))\n",
    "t = np.ones(shape=(3,1))\n",
    "r[1][0] = V_selected[0]/gamma\n",
    "r[1][1] = V_selected[1]/gamma\n",
    "r[1][2] = V_selected[2]/gamma\n",
    "t[1] = V_selected[3]/gamma\n",
    "r[0][0] = (V_selected[4]/alfa)/gamma\n",
    "r[0][1] = (V_selected[5]/alfa)/gamma\n",
    "r[0][2] = (V_selected[6]/alfa)/gamma\n",
    "t[0] = (V_selected[7]/alfa)/gamma"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6. Compute the third row of $R$ as the vector product of the first two rows estimated in the previous step, and enforce the orthogonality constraint on the estimate of $R$ through SVD decomposition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#compute the third row of r\n",
    "r[2,:] = np.cross(r[0,:],r[1,:])\n",
    "\n",
    "#force orthogonality\n",
    "u,d,v = np.linalg.svd(r, full_matrices=True, compute_uv=True)\n",
    "r = np.dot(np.dot(u,np.identity(3)),v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7. Pick a point for which $(x - \\sigma_{x})$ is noticeably different from $0$. If inequality (6.12) is satisfied, reverse the sign of the first two rows of $R$ and the first two components of $T$.\n",
    "![](./imgs/trucco6.12.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#verifying the signal of gamma\n",
    "x_aux = imgpoints[1][0] * (r[0][0] * worldpoints[1][0] + r[0][1] * worldpoints[1][1] +\n",
    "                                    r[0][2] * worldpoints[1][2] + t[0])\n",
    "\n",
    "if x_aux > 0:\n",
    "    r[0,:] = -r[0,:]\n",
    "    r[1,:] = -r[1,:]\n",
    "    t[0:2] = -t[0:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8. Set up $A$ and $b$ of system (6.14), and use (6.15) to estimate $T_{z}$ and $f_{x}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create the matrix A\n",
    "A_2 = []\n",
    "for worldpoint,imgpoint in zip(worldpoints,imgpoints):\n",
    "    A_line = []\n",
    "    A_line.append(imgpoint[0])\n",
    "    A_line.append(r[0][0] * worldpoint[0] + r[0][1] * worldpoint[1] + r[0][2] * worldpoint[2] + t[0][0])\n",
    "    A_2.append(A_line)\n",
    "A_2 = np.asarray(A_2)\n",
    "\n",
    "#create the vector b\n",
    "b = []\n",
    "for worldpoint,imgpoint in zip(worldpoints,imgpoints):\n",
    "        b.append(-imgpoint[0]* (r[2][0] * worldpoint[0] + r[2][1] * worldpoint[1] + r[2][2] * worldpoint[2]))\n",
    "\n",
    "b = np.asarray(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#estimating tz and fx\n",
    "tf = np.dot(np.linalg.pinv(A_2),b)\n",
    "c = np.dot(A_2[2],tf)\n",
    "c = c/b[2]\n",
    "tf = tf/c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Estimated values for $T_{z}$ and $f_{x}$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tz =  286.77342294919174 \n",
      "fx =  3333.6593046214975\n"
     ]
    }
   ],
   "source": [
    "print (\"Tz = \",tf[0],\"\\nfx = \",tf[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discussion\n",
    "\n",
    "Our method was able to achieve acceptably similar results to the ones estimated by the MATLAB algorithm. However, it was surprising for us to notice that the manually calculated focus length value was closer to the MATLAB's than ours. This observation can be the result of both inaccuracies in our image points localization system and abnormal accuracy of the manual method, that maybe cannot be reproduced in other situations due to its lack of robustness."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
