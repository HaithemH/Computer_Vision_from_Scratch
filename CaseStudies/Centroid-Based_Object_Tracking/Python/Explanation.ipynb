{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementing centroid tracking with OpenCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the necessary packages\n",
    "from scipy.spatial import distance as dist\n",
    "from collections import OrderedDict\n",
    "import numpy as np\n",
    " \n",
    "class CentroidTracker():\n",
    "    def __init__(self, maxDisappeared=50):\n",
    "        # initialize the next unique object ID along with two ordered\n",
    "        # dictionaries used to keep track of mapping a given object\n",
    "        # ID to its centroid and number of consecutive frames it has\n",
    "        # been marked as \"disappeared\", respectively\n",
    "        self.nextObjectID = 0\n",
    "        self.objects = OrderedDict()\n",
    "        self.disappeared = OrderedDict()\n",
    "\n",
    "        # store the number of maximum consecutive frames a given\n",
    "        # object is allowed to be marked as \"disappeared\" until we\n",
    "        # need to deregister the object from tracking\n",
    "        self.maxDisappeared = maxDisappeared\n",
    "        \n",
    "    def register(self, centroid):\n",
    "        # when registering an object we use the next available object\n",
    "        # ID to store the centroid\n",
    "        self.objects[self.nextObjectID] = centroid\n",
    "        self.disappeared[self.nextObjectID] = 0\n",
    "        self.nextObjectID += 1\n",
    "        \n",
    "    def deregister(self, objectID):\n",
    "        # to deregister an object ID we delete the object ID from\n",
    "        # both of our respective dictionaries\n",
    "        del self.objects[objectID]\n",
    "        del self.disappeared[objectID]\n",
    "        \n",
    "    def update(self, rects):\n",
    "        # check to see if the list of input bounding box rectangles\n",
    "        # is empty\n",
    "        if len(rects) == 0:\n",
    "            # loop over any existing tracked objects and mark them\n",
    "            # as disappeared\n",
    "            for objectID in list(self.disappeared.keys()):\n",
    "                self.disappeared[objectID] += 1\n",
    "\n",
    "                # if we have reached a maximum number of consecutive\n",
    "                # frames where a given object has been marked as\n",
    "                # missing, deregister it\n",
    "                if self.disappeared[objectID] > self.maxDisappeared:\n",
    "                    self.deregister(objectID)\n",
    " \n",
    "            # return early as there are no centroids or tracking info\n",
    "            # to update\n",
    "            return self.objects\n",
    "        \n",
    "        # initialize an array of input centroids for the current frame\n",
    "        inputCentroids = np.zeros((len(rects), 2), dtype=\"int\")\n",
    "\n",
    "        # loop over the bounding box rectangles\n",
    "        for (i, (startX, startY, endX, endY)) in enumerate(rects):\n",
    "            # use the bounding box coordinates to derive the centroid\n",
    "            cX = int((startX + endX) / 2.0)\n",
    "            cY = int((startY + endY) / 2.0)\n",
    "            inputCentroids[i] = (cX, cY)\n",
    "            \n",
    "        # if we are currently not tracking any objects take the input\n",
    "        # centroids and register each of them\n",
    "        if len(self.objects) == 0:\n",
    "            for i in range(0, len(inputCentroids)):\n",
    "                self.register(inputCentroids[i])\n",
    "                \n",
    "        # otherwise, are are currently tracking objects so we need to\n",
    "        # try to match the input centroids to existing object\n",
    "        # centroids\n",
    "        else:\n",
    "            # grab the set of object IDs and corresponding centroids\n",
    "            objectIDs = list(self.objects.keys())\n",
    "            objectCentroids = list(self.objects.values())\n",
    "\n",
    "            # compute the distance between each pair of object\n",
    "            # centroids and input centroids, respectively -- our\n",
    "            # goal will be to match an input centroid to an existing\n",
    "            # object centroid\n",
    "            D = dist.cdist(np.array(objectCentroids), inputCentroids)\n",
    "\n",
    "            # in order to perform this matching we must (1) find the\n",
    "            # smallest value in each row and then (2) sort the row\n",
    "            # indexes based on their minimum values so that the row\n",
    "            # with the smallest value is at the *front* of the index\n",
    "            # list\n",
    "            rows = D.min(axis=1).argsort()\n",
    "\n",
    "            # next, we perform a similar process on the columns by\n",
    "            # finding the smallest value in each column and then\n",
    "            # sorting using the previously computed row index list\n",
    "            cols = D.argmin(axis=1)[rows]\n",
    "            \n",
    "            # in order to determine if we need to update, register,\n",
    "            # or deregister an object we need to keep track of which\n",
    "            # of the rows and column indexes we have already examined\n",
    "            usedRows = set()\n",
    "            usedCols = set()\n",
    "\n",
    "            # loop over the combination of the (row, column) index\n",
    "            # tuples\n",
    "            for (row, col) in zip(rows, cols):\n",
    "                # if we have already examined either the row or\n",
    "                # column value before, ignore it\n",
    "                # val\n",
    "                if row in usedRows or col in usedCols:\n",
    "                    continue\n",
    " \n",
    "                # otherwise, grab the object ID for the current row,\n",
    "                # set its new centroid, and reset the disappeared\n",
    "                # counter\n",
    "                objectID = objectIDs[row]\n",
    "                self.objects[objectID] = inputCentroids[col]\n",
    "                self.disappeared[objectID] = 0\n",
    " \n",
    "                # indicate that we have examined each of the row and\n",
    "                # column indexes, respectively\n",
    "                usedRows.add(row)\n",
    "                usedCols.add(col)\n",
    "                \n",
    "            # compute both the row and column index we have NOT yet\n",
    "            # examined\n",
    "            unusedRows = set(range(0, D.shape[0])).difference(usedRows)\n",
    "            unusedCols = set(range(0, D.shape[1])).difference(usedCols)\n",
    "            \n",
    "            # in the event that the number of object centroids is\n",
    "            # equal or greater than the number of input centroids\n",
    "            # we need to check and see if some of these objects have\n",
    "            # potentially disappeared\n",
    "            if D.shape[0] >= D.shape[1]:\n",
    "                # loop over the unused row indexes\n",
    "                for row in unusedRows:\n",
    "                    # grab the object ID for the corresponding row\n",
    "                    # index and increment the disappeared counter\n",
    "                    objectID = objectIDs[row]\n",
    "                    self.disappeared[objectID] += 1\n",
    " \n",
    "                    # check to see if the number of consecutive\n",
    "                    # frames the object has been marked \"disappeared\"\n",
    "                    # for warrants deregistering the object\n",
    "                    if self.disappeared[objectID] > self.maxDisappeared:\n",
    "                        self.deregister(objectID)\n",
    "                        \n",
    "            # otherwise, if the number of input centroids is greater\n",
    "            # than the number of existing object centroids we need to\n",
    "            # register each new input centroid as a trackable object\n",
    "            else:\n",
    "                for col in unusedCols:\n",
    "                    self.register(inputCentroids[col])\n",
    " \n",
    "        # return the set of trackable objects\n",
    "        return self.objects"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On Lines 2-4 we import our required packages and modules — distance , OrderedDict , and numpy .\n",
    "\n",
    "Our ***CentroidTracker***  class is defined on Line 6. The constructor accepts a single parameter, the maximum number of consecutive frames a given object has to be lost/disappeared for until we remove it from our tracker (Line 7).\n",
    "\n",
    "***Constructor*** builds four class variables:\n",
    "\n",
    "* nextObjectID : A counter used to assign unique IDs to each object (Line 12). In the case that an object leaves the frame and does not come back for maxDisappeared  frames, a new (next) object ID would be assigned.\n",
    "  \n",
    "  \n",
    "* objects : A dictionary that utilizes the object ID as the key and the centroid (x, y)-coordinates as the value (Line 13).\n",
    "  \n",
    "  \n",
    "* disappeared : Maintains number of consecutive frames (value) a particular object ID (key) has been marked as “lost”for (Line 14).\n",
    "  \n",
    "  \n",
    "* maxDisappeared : The number of consecutive frames an object is allowed to be marked as “lost/disappeared” until we deregister the object."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ***register***  method is defined on Line 21. register method is responsible for adding new objects to our tracker: It accepts a centroid  and then adds it to the objects dictionary using the next available object ID.\n",
    "\n",
    "The number of times an object has disappeared is initialized to 0  in the disappeared  dictionary (Line 25).\n",
    "\n",
    "Finally, we increment the nextObjectID  so that if a new object comes into view, it will be associated with a unique ID (Line 26)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just like we can add new objects to our tracker, we also need the ability to remove old ones that have been lost or disappeared from our the input frames themselves.\n",
    "\n",
    "The ***deregister***  method is defined on Line 28. It simply deletes the objectID  in both the objects  and disappeared  dictionaries, respectively (Lines 31 and 32)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ***update*** method, defined on Line 34, accepts a list of bounding box rectangles, presumably from an object detector (Haar cascade, HOG + Linear SVM, SSD, Faster R-CNN, etc.). The format of the rects  parameter is assumed to be a tuple with this structure: (startX, startY, endX, endY) .\n",
    "\n",
    "If there are no detections, we’ll loop over all object IDs and increment their disappeared  count (Lines 37-41). We’ll also check if we have reached the maximum number of consecutive frames a given object has been marked as missing. If that is the case we need to remove it from our tracking systems (Lines 46 and 47). Since there is no tracking info to update, we go ahead and return  early on Line 51\n",
    "\n",
    "Otherwise, we have quite a bit of work to do over the next seven code blocks in the update  method:\n",
    "\n",
    "On Line 54 we’ll initialize a NumPy array to store the centroids for each rect .\n",
    "\n",
    "Then, we loop over bounding box rectangles (Line 57) and compute the centroid and store it in the inputCentroids  list (Lines 59-61).\n",
    "\n",
    "If there are currently no objects we are tracking, we’ll register each of the new objects:\n",
    "\n",
    "Otherwise, we need to update any existing object (x, y)-coordinates based on the centroid location that minimizes the Euclidean distance between them:\n",
    "\n",
    "The updates to existing tracked objects take place beginning at the else  on Line 72. The goal is to track the objects and to maintain correct object IDs — this process is accomplished by computing the Euclidean distances between all pairs of objectCentroids  and inputCentroids , followed by associating object IDs that minimize the Euclidean distance.\n",
    "\n",
    "Inside of the else block beginning on Line 72, we will:\n",
    "\n",
    "* Grab objectIDs  and objectCentroid  values (Lines 74 and 75).\n",
    "\n",
    "\n",
    "* Compute the distance between each pair of existing object centroids and new input centroids (Line 81). The output NumPy array shape of our distance map D  will be (# of object centroids, # of input centroids) .\n",
    "\n",
    "\n",
    "* To perform the matching we must (1) Find the smallest value in each row, and (2) Sort the row indexes based on the minimum values (Line 88). We perform a very similar process on the columns, finding the smallest value in each column, and then sorting them based on the ordered rows (Line 93). Our goal is to have the index values with the smallest corresponding distance at the front of the lists.\n",
    "\n",
    "\n",
    "Then\n",
    "\n",
    "* Initialize two sets to determine which row and column indexes we have already used (Lines 98 and 99). Keep in mind that a set is similar to a list but it contains only unique values.\n",
    "\n",
    "\n",
    "* Then we loop over the combinations of (row, col)  index tuples (Line 103) in order to update our object centroids:\n",
    "\n",
    "    * If we’ve already used either this row or column index, ignore it and continue  to loop (Lines 107 and 108).\n",
    "    \n",
    "    * Otherwise, we have found an input centroid that:\n",
    "        * Has the smallest Euclidean distance to an existing centroid\n",
    "        * And has not been matched with any other object\n",
    "        * In that case, we update the object centroid (Lines 113-115) and make sure to add the row  and col  to their respective usedRows  and usedCols  sets\n",
    "        \n",
    "        \n",
    "There are likely indexes in our usedRows  + usedCols  sets that we have NOT examined yet:\n",
    "\n",
    "So we must determine which centroid indexes we haven’t examined yet and store them in two new convenient sets ( unusedRows  and unusedCols ) on Lines 124 and 125.\n",
    "\n",
    "Our final check handles any objects that have become lost or if they’ve potentially disappeared:\n",
    "\n",
    "\n",
    "To finish up:\n",
    "\n",
    "* If the number of object centroids is greater than or equal to the number of input centroids (Line 131):\n",
    "    * We need to verify if any of these objects are lost or have disappeared by looping over unused row indexes if any (Line 133).\n",
    "    * In the loop, we will:\n",
    "        * Increment their disappeared  count in the dictionary (Line 137).\n",
    "        * Check if the disappeared  count exceeds the maxDisappeared  threshold (Line 142), and, if so we’ll deregister the object (Line 143).\n",
    "        \n",
    "Otherwise, the number of input centroids is greater than the number of existing object centroids, so we have new objects to register and track:\n",
    "\n",
    "We loop over the unusedCols  indexes (Line 149) and we register each new centroid (Line 150). Finally, we’ll return the set of trackable objects to the calling method (Line 153)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Understanding the centroid tracking distance relationship"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our centroid tracking implementation was quite long, and admittedly, the most confusing aspect of the algorithm is Lines 81-93.\n",
    "\n",
    "If you’re having trouble following along with what that code is doing you should consider opening a Python shell and performing the following experiment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.82421549, 0.32755369, 0.33198071],\n",
       "       [0.72642889, 0.72506609, 0.17058938]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.spatial import distance as dist\n",
    "import numpy as np\n",
    "np.random.seed(42)\n",
    "objectCentroids = np.random.uniform(size=(2, 2))\n",
    "centroids = np.random.uniform(size=(3, 2))\n",
    "D = dist.cdist(objectCentroids, centroids) # Euclidean distance between the pairs\n",
    "D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementing the object tracking driver script"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have implemented our CentroidTracker  class, let’s put it to work with an object tracking driver script.\n",
    "\n",
    "The driver script is where you can use your own preferred object detector, provided that it produces a set of bounding boxes. This could be a Haar Cascade, HOG + Linear SVM, YOLO, SSD, Faster R-CNN, etc. For this example script, I’m making use of OpenCV’s deep learning face detector, but feel free to make your own version of the script which implements a different detector.\n",
    "\n",
    "Inside this script, we will:\n",
    "\n",
    "* Work with a live VideoStream  object to grab frames from your webcam\n",
    "\n",
    "\n",
    "* Load and utilize OpenCV’s deep learning face detector\n",
    "\n",
    "\n",
    "* Instantiate our CentroidTracker  and use it to track face objects in the video stream\n",
    "\n",
    "\n",
    "* And display our results which includes bounding boxes and object ID annotations overlaid on the frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the necessary packages\n",
    "from tracker.centroidtracker import CentroidTracker\n",
    "from imutils.video import VideoStream\n",
    "import numpy as np\n",
    "import argparse\n",
    "import imutils\n",
    "import time\n",
    "import cv2\n",
    " \n",
    "# construct the argument parse and parse the arguments\n",
    "ap = argparse.ArgumentParser()\n",
    "ap.add_argument(\"-p\", \"--prototxt\", required=True,\n",
    "    help=\"path to Caffe 'deploy' prototxt file\")\n",
    "ap.add_argument(\"-m\", \"--model\", required=True,\n",
    "    help=\"path to Caffe pre-trained model\")\n",
    "ap.add_argument(\"-c\", \"--confidence\", type=float, default=0.5,\n",
    "    help=\"minimum probability to filter weak detections\")\n",
    "args = vars(ap.parse_args())\n",
    "\n",
    "# initialize our centroid tracker and frame dimensions\n",
    "ct = CentroidTracker()\n",
    "(H, W) = (None, None)\n",
    " \n",
    "# load our serialized model from disk\n",
    "print(\"[INFO] loading model...\")\n",
    "net = cv2.dnn.readNetFromCaffe(args[\"prototxt\"], args[\"model\"])\n",
    " \n",
    "# initialize the video stream and allow the camera sensor to warmup\n",
    "print(\"[INFO] starting video stream...\")\n",
    "vs = VideoStream(src=0).start()\n",
    "time.sleep(2.0)\n",
    "\n",
    "# loop over the frames from the video stream\n",
    "while True:\n",
    "    # read the next frame from the video stream and resize it\n",
    "    frame = vs.read()\n",
    "    frame = imutils.resize(frame, width=400)\n",
    " \n",
    "    # if the frame dimensions are None, grab them\n",
    "    if W is None or H is None:\n",
    "        (H, W) = frame.shape[:2]\n",
    " \n",
    "    # construct a blob from the frame, pass it through the network,\n",
    "    # obtain our output predictions, and initialize the list of\n",
    "    # bounding box rectangles\n",
    "    blob = cv2.dnn.blobFromImage(frame, 1.0, (W, H),\n",
    "        (104.0, 177.0, 123.0))\n",
    "    net.setInput(blob)\n",
    "    detections = net.forward()\n",
    "    rects = []\n",
    "    \n",
    "    # loop over the detections\n",
    "    for i in range(0, detections.shape[2]):\n",
    "        # filter out weak detections by ensuring the predicted\n",
    "        # probability is greater than a minimum threshold\n",
    "        if detections[0, 0, i, 2] > args[\"confidence\"]:\n",
    "            # compute the (x, y)-coordinates of the bounding box for\n",
    "            # the object, then update the bounding box rectangles list\n",
    "            box = detections[0, 0, i, 3:7] * np.array([W, H, W, H])\n",
    "            rects.append(box.astype(\"int\"))\n",
    " \n",
    "            # draw a bounding box surrounding the object so we can\n",
    "            # visualize it\n",
    "            (startX, startY, endX, endY) = box.astype(\"int\")\n",
    "            cv2.rectangle(frame, (startX, startY), (endX, endY),\n",
    "                (0, 255, 0), 2)\n",
    "            \n",
    "    # update our centroid tracker using the computed set of bounding\n",
    "    # box rectangles\n",
    "    objects = ct.update(rects)\n",
    " \n",
    "    # loop over the tracked objects\n",
    "    for (objectID, centroid) in objects.items():\n",
    "        # draw both the ID of the object and the centroid of the\n",
    "        # object on the output frame\n",
    "        text = \"ID {}\".format(objectID)\n",
    "        cv2.putText(frame, text, (centroid[0] - 10, centroid[1] - 10),\n",
    "            cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "        cv2.circle(frame, (centroid[0], centroid[1]), 4, (0, 255, 0), -1)\n",
    " \n",
    "    # show the output frame\n",
    "    cv2.imshow(\"Frame\", frame)\n",
    "    key = cv2.waitKey(1) & 0xFF\n",
    " \n",
    "    # if the `q` key was pressed, break from the loop\n",
    "    if key == ord(\"q\"):\n",
    "        break\n",
    "\n",
    "# do a bit of cleanup\n",
    "cv2.destroyAllWindows()\n",
    "vs.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we specify our imports. Most notably we’re using the CentroidTracker  class that we just reviewed. We’re also going to use VideoStream  from imutils  and OpenCV.\n",
    "\n",
    "We have three command line arguments which are all related to our deep learning face detector:\n",
    "\n",
    "* --prototxt : The path to the Caffe “deploy” prototxt.\n",
    "\n",
    "\n",
    "* --model : The path to the pre-trained model models.\n",
    "\n",
    "\n",
    "* --confidence : Our probability threshold to filter weak detections. I found that a default value of 0.5  is sufficient.\n",
    "\n",
    "The prototxt and model files come from OpenCV’s repository \n",
    "\n",
    "***Note:*** In case you missed it at the start of this section, I’ll repeat that you can use any detector you wish. As an example, we’re using a deep learning face detector which produces bounding boxes. Feel free to experiment with other detectors, just be sure that you have capable hardware to keep up with the more complex ones (some may run best with a GPU, but this face detector can easily run on a CPU).\n",
    "\n",
    "Next, let’s perform our initializations:\n",
    "\n",
    "* Instantiate our CentroidTracker , ct  (Line 21). Recall from the explanation in the previous section that this object has three methods: (1) register , (2) deregister , and (3) update . We’re only going to use the update  method as it will register and deregister objects automatically. We also initialize H  and W  (our frame dimensions) to None  (Line 22).\n",
    "\n",
    "\n",
    "* Load our serialized deep learning face detector model from disk using OpenCV’s DNN module (Line 26).\n",
    "\n",
    "\n",
    "* Start our VideoStream , vs  (Line 30). With vs  handy, we’ll be able to capture frames from our camera in our next while  loop. We’ll allow our camera 2.0  seconds to warm up (Line 31).\n",
    "\n",
    "Now let’s begin our while  loop and start tracking face objects:\n",
    "\n",
    "We loop over frames and resize  them to a fixed width (while preserving aspect ratio) on Lines 34-47. Our frame dimensions are grabbed as needed (Lines 40 and 41).\n",
    "\n",
    "Then we pass the frame through the CNN object detector to obtain predictions and object locations (Lines 46-49).\n",
    "\n",
    "We initialize a list of rects , our bounding box rectangles on Line 50.\n",
    "\n",
    "From there, let’s process the detections:\n",
    "\n",
    "We loop over the detections beginning on Line 53. If the detection exceeds our confidence threshold, indicating a valid detection, we:\n",
    "\n",
    "* Compute the bounding box coordinates and append them to the rects  list (Lines 59 and 60)\n",
    "\n",
    "\n",
    "* Draw a bounding box around the object (Lines 64-66)\n",
    "\n",
    "\n",
    "Finally, let’s call update  on our centroid tracker object, ct :\n",
    "\n",
    "The ct.update  call on Line 70 handles the heavy lifting in our simple object tracker with Python and OpenCV script.\n",
    "\n",
    "We would be done here and ready to loop back to the top if we didn’t care about visualization.\n",
    "\n",
    "But that’s no fun!\n",
    "\n",
    "On Lines 73-79 we display the centroid as a filled in circle and the unique object ID number text. Now we’ll be able to visualize the results and check to see if our CentroidTracker  properly keeps track of our objects by associating the correct IDs with the objects in the video stream.\n",
    "\n",
    "We’ll display the frame on Line 82 until the quit key (“q”) has been pressed (Lines 83-87). If the quit key is pressed, we simply  break  and perform cleanup (Lines 87-91)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
